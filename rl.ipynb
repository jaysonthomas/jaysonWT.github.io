{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EgiF12Hf1Dhs"
   },
   "source": [
    "This notebook provides examples to go along with the [textbook](http://manipulation.csail.mit.edu/rl.html).  I recommend having both windows open, side-by-side!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from pydrake.all import Rgba, RigidTransform, Sphere, StartMeshcat\n",
    "\n",
    "from manipulation.meshcat_cpp_utils import plot_surface\n",
    "from manipulation.utils import LoadDataResource, running_as_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshcat = StartMeshcat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define a few interesting cost functions that have multiple local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_hump_camel(x, y, path=None):\n",
    "    z = (2 * x**2 - 1.05 * x**4 + x**6 / 6 + x * y + y**2) / 4\n",
    "    if path:\n",
    "        pt = f\"{path}/{x}_{y}\"\n",
    "        meshcat.SetObject(pt, Sphere(0.01), Rgba(0, 0, 1, 1))\n",
    "        meshcat.SetTransform(pt, RigidTransform([x, y, z]))\n",
    "    return z\n",
    "\n",
    "def plot_three_hump_camel():\n",
    "    X, Y = np.meshgrid(np.arange(-2.5, 2.5, 0.05), np.arange(-3, 3, 0.05))\n",
    "    Z = three_hump_camel(X,Y)\n",
    "    # TODO(russt): Finish the per-vertex coloring variant.\n",
    "    plot_surface(meshcat, \"three_hump_camel\", X, Y, Z, wireframe=True)\n",
    "\n",
    "def six_hump_camel(x, y, path=None):\n",
    "    z = x**2 * (4 - 2.1 * x**2 + x**4 / 3) + x * y + y**2 * (-4 + 4 * y**2)\n",
    "    if path:\n",
    "        pt = f\"{path}/{x}_{y}\"\n",
    "        meshcat.SetObject(pt, Sphere(0.01), Rgba(0, 0, 1, 1))\n",
    "        meshcat.SetTransform(pt, RigidTransform([x, y, z]))\n",
    "    return z\n",
    "\n",
    "def plot_six_hump_camel():\n",
    "    X, Y = np.meshgrid(np.arange(-2, 2, 0.05), np.arange(-1.2, 1.2, 0.05))\n",
    "    Z = six_hump_camel(X,Y)\n",
    "    # TODO(russt): Finish the per-vertex coloring variant.\n",
    "    plot_surface(meshcat, \"six_hump_camel\", X, Y, Z, wireframe=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black-box optimization\n",
    "\n",
    "Let's explore a few of the algorithms from Nevergrad on these simple cost landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat nevergrad as an optional dependency.\n",
    "# TODO(russt): Consume nevergrad without the (heavy) bayesian-optimization dependency.\n",
    "if 'nevergrad' in sys.modules:\n",
    "    import nevergrad as ng\n",
    "\n",
    "    meshcat.Delete()\n",
    "    plot_six_hump_camel()\n",
    "\n",
    "    # Note: You can print nevergrad's available optimizers using\n",
    "    # print(sorted(ng.optimizers.registry.keys()))\n",
    "\n",
    "    # Uncomment some of these to try...\n",
    "    #solver='NGOpt'\n",
    "    #solver='RandomSearch'\n",
    "    solver='CMA'\n",
    "    optimizer = ng.optimizers.registry[solver](parametrization=2, budget=100)\n",
    "    recommendation = optimizer.minimize(\n",
    "        lambda x: six_hump_camel(x[0], x[1], \"NGOpt\"))\n",
    "    xstar = recommendation.value\n",
    "    meshcat.SetObject(\"recommendation\", Sphere(0.02), Rgba(0, 1, 0, 1))\n",
    "    meshcat.SetTransform(\"recommendation\", RigidTransform(\n",
    "        [xstar[0], xstar[1], six_hump_camel(xstar[0], xstar[1])]))\n",
    "    print(xstar)  # recommended value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshcat.Delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL for box flip-up\n",
    "\n",
    "## State-feedback policy via PPO (with stiffness control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.envs.register(id=\"BoxFlipUp-v0\",\n",
    "                  entry_point=\"manipulation.envs.box_flipup:BoxFlipUpEnv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "observations = \"state\"\n",
    "env = gym.make(\"BoxFlipUp-v0\", observations=observations)\n",
    "\n",
    "use_pretrained_model = False\n",
    "if use_pretrained_model:\n",
    "    # Note: Models saved in stable baselines are version specific.  This one \n",
    "    # requires python3.6 (and cloudpickle==1.6.0).\n",
    "    # TODO(russt): Save a trained model that works on Deepnote.\n",
    "    model = PPO.load(LoadDataResource('box_flipup_ppo_state_3.zip'), env)\n",
    "elif running_as_notebook:\n",
    "    # This is a relatively small amount of training.  See rl_train_boxflipup.py \n",
    "    # for a version that runs the heavyweight version with multiprocessing.\n",
    "    model = PPO('MlpPolicy', env, verbose=1)\n",
    "    model.learn(total_timesteps=100000)\n",
    "else:\n",
    "    # For testing this notebook, we simply want to make sure that the code runs.\n",
    "    model = PPO('MlpPolicy', env, n_steps=4, n_epochs=2, batch_size=8)\n",
    "    model.learn(total_timesteps=4)\n",
    "\n",
    "# Make a version of the env with meshcat.\n",
    "env = gym.make(\"BoxFlipUp-v0\", meshcat=meshcat, observations=observations)\n",
    "\n",
    "if running_as_notebook:\n",
    "    env.simulator.set_target_realtime_rate(1.0)\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(500 if running_as_notebook else 5):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "      obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "Q, Qdot = np.meshgrid(np.arange(0, np.pi, 0.05), np.arange(-2, 2, 0.05))\n",
    "# TODO(russt): tensorize this...\n",
    "V = 0*Q\n",
    "for i in range(Q.shape[0]):\n",
    "    for j in range(Q.shape[1]):\n",
    "        obs[2] = Q[i,j]\n",
    "        obs[7] = Qdot[i,j]\n",
    "        with torch.no_grad():\n",
    "            V[i, j] = model.policy.predict_values(\n",
    "                model.policy.obs_to_tensor(obs)[0])[0].cpu().numpy()[0]\n",
    "V = V - np.min(np.min(V))\n",
    "V = V / np.max(np.max(V))\n",
    "\n",
    "meshcat.Delete()\n",
    "meshcat.ResetRenderMode()\n",
    "plot_surface(meshcat, \"Critic\", Q, Qdot, V, wireframe=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Robotic Manipulation - Geometric Pose Estimation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
