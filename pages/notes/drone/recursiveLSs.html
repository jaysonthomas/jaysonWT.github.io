
<!DOCTYPE html>
<html>
<head>
  <title>Recursive least squares</title>
  <meta name="Recursive least squares" content="text/html; charset=utf-8;" />
  <script type="text/javascript" src="../../../logbook.js"></script>

  <script src="../../../logbook-mathjax-config.js" defer></script> 
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/atom-one-light.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <link rel="stylesheet" type="text/css" href="../../../logbook.css" />
</head>

<body onload="loadChapter('');">  

  <div data-type="titlepage" pdf="no">
    <header>
      <h1><a href="../../../index.html" style="text-decoration:none;">Logbook</a></h1>
      <p style="font-size: 18px;"><a href="../../../bio/jjwt.html">Jayson Wynne-Thomas</a></p>
      <p style="font-size: 14px; text-align: right;"> 
        Last modified <span id="last_modified"></span>.</br>
        <script>
        var d = new Date(document.lastModified);
        document.getElementById("last_modified").innerHTML = d.getFullYear() + "-" + (d.getMonth()+1) + "-" + d.getDate();</script>
      </p>
    </header>
  </div>

  <table style="width:100%;" pdf="no"><tr style="width:100%">
    <td style="width:33%;text-align:left;">
      <a class="previous_chapter" href="">Prev Chapter</a>
    </td>
    
    <td style="width:33%;text-align:center;">
      <a href="">Root Chapter</a>
    </td>
    
    <td style="width:33%;text-align:right;">
      <a class="next_chapter" href="">Next Chapter</a>
    </td>
  </tr></table>
  
  <div id="main" class="sidebar1">
    <span style="font-size:10px;cursor:pointer" onclick="openNav()">&#9776;</span>
  </div>

  <div id="mySidenav" class="sidebar">
  
<a href="#0">Table of Contents</a>
<a href="#1">Overview</a>
<a href="#2">Linear recursive estimator</a>
<a href="#3">Computing the estimator gain matrix $K_k$</a>
<a href="#4">RLS algorithm</a>
<a href="#5">Summary</a>
<a href="#6">RLS from another view point</a>
<ul class="no-bullets">
  <li><a href="#6.0">Description</a></li>
  <li><a href="#6.1">Finding $p(x|y)$</a></li>
  <li><a href="#6.2">Choosing $\hat{x}$</a></li>
</ul>
</div>

<chapter style="counter-reset: chapter 0"><h1>Recursive least squares</h1>

<section id="0"><h1>Table of Contents</h1>
  <ul>
    <li><a href="#1">Overview</a></li>
  </ul>
</section>

<section id="1"><h1>Overview</h1>
  RLS extends the batch LS solution to work on the fly by keeping a running estimate of the
  optimal parameter (the LS solution) for all measurements collected up to the previous 
  time step and then updates the estimate given the measurement at the current time step.  
  Thus the estimate is updated incrementally as new measurements stream in. 
  
  <p>
    Ideally, we'd like to have as 
    many measurements as possible to get an accurate estimate. But, the amount of 
    computational resources needed to solve 
    the normal equations will grow with the measurement vector size. For this reason, having
    a batch of stored measurements is not a good idea.  
  </p>
</section>

<section id="2"><h1>Linear recursive estimator</h1>
  Let us assume that we have our best optimal estimate of our unknown parameters at time $k-1$. 
  At time $k$ we receive a new measurement that we will assume follows a linear measurement 
  model with additive Gaussian noise. 

  $$
    y_k = H_kx + v_k
  $$
  
  Our goal is to compute an updated optimal estimate at 
  time $k$, given our measurement $y_k$ and the previous estimate $\hat{x}_{k-1}$. 
  <p></p>

  A linear recursive estimate is given by the following expression:
  
  $$
    \hat{x}_k = \hat{x}_{k-1} + 
    \underbrace{K_k}_{\text{Estimator} \atop \text{gain matrix}}
    \underbrace{(y_k - H_k\hat{x}_{k-1})}_{\text Innovation}
  $$
  <code>Innovation</code> quantifies how well our current measurement matches our previous 
  best estimate. 
  
  <p>
    We update our new state (estimate) as a linear combination of the previous estimate 
    (best guess) and the current measurement residual (or error, 
    difference between what we expected the measurement to be and what we actually measured),
    weighted by a gain matrix $K_k$
    If the innovation were equal to $0$, we would not change our old estimate at all. 
  </p>
</section>

<section id="3"><h1>Computing the estimator gain matrix $K_k$</h1>
  We can compute it by minimising a similar LSs criterion, but this time we'll use a
  probabilistic formulation. We wish to minimise the expected value of the sum of squared
  errors of our current estimate at time step $k$.

  <p>
    For a single scalar parameter like resistance, this amounts to minimising the estimator 
    state variance:
  </p>
  $$\begin{align*}
    \mathcal L_{RLS} &= \mathbb{E}[(x_k - \hat{x}_k)^2] \\
    &= \sigma^2_k
  \end{align*}$$

  For multiple $n$ unknown parameters, this is equivalent 
  to minimising the trace of our state covariance matrix at time step $k$: 
  
  $$\begin{align*}
    \mathcal L_{RLS} &= \mathbb{E}[(x_{1k} - \hat{x}_{1k})^2
    + \cdots + (x_{nk} - \hat{x}_{nk})^2] \\
    &= Trace(\underbrace{P_k}_{\text Estimator \atop \text covariance})
  \end{align*}$$
  
  Instead of minimising the error directly, we minimise its expected value which is actually 
  the estimator variance. The lower the variance, the more we are certain of our estimate. 
  
  <p>
    Using our linear recursive formulation, we can express the state covariance matrix $P_k$
    as a function of $K_k$:

    $$
      P_k = (1-K_kH_k)P_{k-1}(1-K_kH_k)^T + K_kR_kK^T_k
    $$  
  </p>
  
  By using matrix calculus and taking derivatives, we can show that this criterion is minimised 
  when $K_k$ has the following value: (find the full derivation in any standard estimation text)

  $$
    K_k = P_{k-1}H^T_k(H_kP_{k-1}H^T_k + R_k)^{-1}
  $$
  
  Finally, by using this formulation, we can also rewrite our recursive definition for 
  $P_k$ into something much simpler. 

  $$\begin{align*}
    P_k &= P_{k-1} - K_kH_kP_{k-1} \\
    &= (1-K_kH_k)P_{k-1}
  \end{align*}$$
  
  The larger the gain matrix $K$, the smaller the new estimator covariance will be. 
  Intuitively, the gain matrix balances the information we get from the 
  prior estimate and the information we receive from the new measurement. 
</section>

<section id="4"><h1>RLS algorithm</h1>
  <ul>
    <li>Initialise the estimator</li>
    Initialise the estimate of the unknown parameters and the corresponding covariance 
    matrices.

    $$\begin{align*}
      \hat{x}_0 &= \mathbb{E}[x] \\
      P_0 &= \mathbb{E}[(x-\hat{x}_0)(x-\hat{x}_0)^T]
    \end{align*}$$
  </ul>
  This initial guess could come from the first measurement we take and the 
  covariance could come from technical specifications. 
  
  <p>
    <li>
      Set up the measurement model, defining the Jacobian and the measurement 
      covariance matrix
    </li>
    $$
      y_k = H_kx + v_k
    $$
  </p>

  <li>Update the estimate $\hat{x}_k$ and the covariance $P_k$</li>
  For every measurement $k$:
  $$\begin{align*}
    K_k &= P_{k-1}H^T_k(H_kP_{k-1}H^T_k + R_k)^{-1} \\
    \hat{x}_k &= \hat{x}_{k-1} + K_k(y_k - H_k\hat{x}_{k-1}) \\
    P_k &= (1-K_kH_k)P_{k-1}
  \end{align*}$$
  
  Every time a measurement is recorded, we compute the measurement gain and then 
  use it to update the estimate of the parameters and the estimator covariance or uncertainty. 
  Every time we get a new measurement our parameter uncertainty shrinks. 
</section>

<section id="5"><h1>Summary</h1>
  RLS enables us to 
  minimise computational effort in our estimation process. More 
  importantly, it forms the update step of the linear Kalman filter. 
  RLS lets us produce a running estimate of a 
  parameter without having to have the entire batch of measurements at hand. It 
  is a recursive linear estimator that minimises the variance of the parameters 
  at the current time. 

  <p>
    In the jupyter notebook, use RLS to determine a voltage value from a series of measurements. 
  </p>
</section>

<section id="6"><h1>RLS from another view point</h1>
  <subsection id="6.0"><h1>Description</h1>
    Instead of coming up with an estimate taking in all the measurements at once, we're going to maintain an estimate, allowing new measurements to update that estimate one at a time.

    <p>
      Let's assume that we have a prior estimate of the vehicle position, given as a Gaussian with an initial estimate $\hat{x}_0$ and covariance $Q_0$. The subscript $0$ denotes the estimate before any measurement is received and subscript $1$ denotes the estimate after one measurement is received.
    </p>

    $$
      p(x) \sim \mathcal{N}(\hat{x}_0, Q_0)
    $$

    How can we actually use this prior in our estimation process? We adopt a very similar approach to the two steps we did before maximum likelihood estimation:

    <ul>
      <li>We first found the probability density function $p(y|x)$</li>
      <li>We selected $x$ to be the value that yielded the maximum likelihood of the measurements, $\tilde{y}$ given $\hat{x}$</li>
    </ul>

    Now that we have a prior, we can find the posterior estimate $p(x|\tilde{y})$. The two steps of the new process are:

    <ul>
      <li>Find the probability density function $p(x|y)$</li>
      <li>Select $\hat{x}$ to be the value that yields the maximum $p(\hat{x}|\tilde{y})$</li>
      <p>
        The output of this recursive estimate is usually referred to as the <i>Maximum A Posteriori (MAP) estimate</i>. We turn the prior into a posterior using new information from the new measurement. 
      </p>
    </ul>
  </subsection>

  <subsection id="6.1"><h1>Finding $p(x|y)$</h1>
    Applying Bayes' rule to Gaussians, we can get:
    $$\begin{align*}
      p(x|y) &= \frac{p(y|x)p(x)}{p(y)} \\
      &= \underbrace{\alpha}_{\text{Normaliser}}
      \underbrace{\mathcal{N}(Hx, R)}_{p(y|x)}
      \underbrace{\mathcal{N}(\hat{x}_0, Q_0)}_{p(x)}
    \end{align*}$$
    
    $p(x)$ is the prior. We can ignore the normaliser alpha just as we did in the maximum likelihood estimate, as it is not going to have any impact on the maximum.
  </subsection>

  <subsection id="6.2"><h1>Choosing $\hat{x}$</h1>
    We select $\hat{x}$ hat to be the value that yields a maximum likelihood of $p(\hat{x}|\tilde{y})$. If we look at the full formula for the product Gaussian:

    $$
      p(\hat{x}|\tilde{y}) = 
      \underbrace{
      \frac{1}
      {(2\pi)^{\frac{n}{2}} \lvert{R}\rvert^{\frac{1}{2}}}
      \frac{1}
      {(2\pi)^{\frac{n}{2}} \lvert{Q_0}\rvert^{\frac{1}{2}}}
      }_{\text{Normalisers}}

      e^\underbrace{{
        -\frac{1}{2}(\tilde{y} - H\hat{x})^T 
        R^{-1}(\tilde{y} - H\hat{x}) 
        - \frac{1}{2}(\hat{x} - \hat{x}_0)^T
        Q_0^{-1}(\hat{x}-\hat{x}_0)
      }}_{\qquad\qquad\qquad\text{Maximise}}
    $$

    We have 2 of the normalizers from the Gaussian. We also have the product of the two exponents, which when we take the product of exponents becomes the exponent of the sum.

    <p>
      Just as before, the normaliser term does not depend on $x$, whereas the exponent does. We take the maximum of the function in the exponent by taking the derivative and finding where it's zero.
    </p>

    The result for this maximum A posteriori estimate is still a Gaussian with an updated mean and covariance:

    $$
      p(\hat{x}|\tilde{y}) \sim \mathcal{N}(\hat{x}_1, Q_1)
    $$

    <ul>
      <li>We first do a covariance update to get $Q_1$</li>
      $$
        Q_1 = (Q_0^{-1} + H^TR^{-1}H)^{-1}
      $$
      $Q_1$ depends on $R$ even if $R$ is defined to be a variance times the identity matrix.

      <p>
        <li>The mean is then updated based on the new covariance</li>
        $$
          \hat{x} = \hat{x}_0 + 
          \underbrace{Q_1}_{\text{Prior} \atop \text{covariance}}
          H^T
          \underbrace{R^{-1}}_{\text{Measurement} \atop \text{covariance}}
          (\tilde{y} - H\hat{x}_0)
        $$

        The MAP estimate $\hat{x}$ is a weighted average between the prior $\hat{x}_0$ and what the new measurement says about $x$, $(\tilde{y} - H\hat{x}_0)$. The weights come from the relative magnitude of the prior and the measurement covariance.

        <p>
          The more we trust the prior estimate, the smaller the prior covariance! And the less the measurements will affect the estimate. The more we trust the measurements, the smaller the measurement covariance and the more the new measurements will change the current estimate.
        </p>

        A balance between prior and new information is the heart of the estimation process.
      </p>
    </ul>    
  </subsection>
</section>

</chapter>

</body>
</html>
