
<!DOCTYPE html>
<html>
<head>
  <title>Basics of pick and place</title>
  <meta name="Basics of pick and place" content="text/html; charset=utf-8;" />
  <script type="text/javascript" src="../../../logbook.js"></script>

  <script src="../../../logbook-mathjax-config.js" defer></script> 
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/atom-one-light.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <link rel="stylesheet" type="text/css" href="../../../logbook.css" />
</head>

<body onload="loadChapter('');">  

  <div data-type="titlepage" pdf="no">
    <header>
      <h1><a href="../../../index.html" style="text-decoration:none;">Logbook</a></h1>
      <p style="font-size: 18px;"><a href="../../../bio/jjwt.html">Jayson Wynne-Thomas</a></p>
      <p style="font-size: 14px; text-align: right;"> 
        Last modified <span id="last_modified"></span>.</br>
        <script>
        var d = new Date(document.lastModified);
        document.getElementById("last_modified").innerHTML = d.getFullYear() + "-" + (d.getMonth()+1) + "-" + d.getDate();</script>
      </p>
    </header>
  </div>

  <table style="width:100%;" pdf="no"><tr style="width:100%">
    <td style="width:33%;text-align:left;">
      <a class="previous_chapter" href="">Prev Chapter</a>
    </td>
    
    <td style="width:33%;text-align:center;">
      <a href="">Root Chapter</a>
    </td>
    
    <td style="width:33%;text-align:right;">
      <a class="next_chapter" href="">Next Chapter</a>
    </td>
  </tr></table>
  
  <div id="main" class="sidebar1">
    <span style="font-size:10px;cursor:pointer" onclick="openNav()">&#9776;</span>
  </div>

  <div id="mySidenav" class="sidebar">
  
<a href="#0">Overview</a>
<ul class="no-bullets">
  <li><a href="#0.0">Basic strategy</a></li>
</ul>
<a href="#1">Notations</a>
<ul class="no-bullets">
  <li><a href="#1.0">Position</a></li>
  <li><a href="#1.1">Orientation</a></li>
  <li><a href="#1.2">Pose</a></li>
  <li><a href="#1.3">Notation understanding check</a></li>
  <li><a href="#1.4">Example usage</a></li>
</ul>
<a href="#2">Frames for pick and place</a>
<ul class="no-bullets">
  <li><a href="#2.0">Timing between key frames</a></li>
</ul>
<a href="#3">Interpolation between poses</a>
<ul class="no-bullets">
  <li><a href="#3.0">Interpolation between positions</a></li>
  <li><a href="#3.1">Problems faced when interpolating between orientations</a></li>
  <li><a href="#3.2">The right way to interpolate between orientations</a></li>
</ul>
<a href="#4">Forward kinematics problem</a>
<ul class="no-bullets">
  <li><a href="#4.0">Description</a></li>
  <li><a href="#4.1">Computing the pose of the EE using FK</a></li>
  <li><a href="#4.2">Defining $q$</a></li>
  <li><a href="#4.3">Drake implementation</a></li>
</ul>
<a href="#5">Inverse kinematics</a>
<a href="#6">Differential IK</a>
<ul class="no-bullets">
  <li><a href="#6.0">Description</a></li>
  <li><a href="#6.1">Spatial velocity</a></li>
  <li><a href="#6.2">Geometric jacobian</a></li>
  <li><a href="#6.3">Joint velocity</a></li>
  <li><a href="#6.4">Inverse Jacobian</a></li>
</ul>
<a href="#7">The controller</a>
<ul class="no-bullets">
  <li><a href="#7.0">Limitations</a></li>
</ul>
<a href="#8">Singularities</a>
<a href="#9">Differential IK as optimisation</a>
<ul class="no-bullets">
  <li><a href="#9.0">Simple linear example - scalar case</a></li>
  <li><a href="#9.1">Simple linear example - vector/matrix case</a></li>
  <li><a href="#9.2">Adding limits/boundaries</a></li>
</ul>
<a href="#10">Summary of the usefulness of optimisation</a>
<a href="#11">Example</a>
<a href="#12">Closing remarks</a>
<ul class="no-bullets">
  <li><a href="#12.0">QP formulation 1</a></li>
  <li><a href="#12.1">QP formulation 2</a></li>
  <li><a href="#12.2">Comparison of the 2 formulations</a></li>
</ul>
</div>

<chapter style="counter-reset: chapter 3"><h1>Basics of pick and place</h1>

<section id="0"><h1>Overview</h1>
  <ul>
    <li>Getting the notations right</li>
    Even in deep neural networks (say to calculate pose estimation), we're going to have a kinematics problem at some point and we're going to have a bug where the vectors are pointing the wrong way etc. If we get the notations right, spatial algebra will protect us.

    <p>
      <li>Choosing our frames</li>
      We have a gripper and a gripper frame; an object and an object frame. To grasp, we need to get the gripper frame in the right relative orientation and position to the object frame. 
    </p>

    <li>Trajectory generation</li>
    We'll plot the frames for the open-loop trajectory of the gripper picking up and dropping off the brick at the desired location. We forget the rest of the robot and just decide the different trajectory of poses the hand needs to go through in space at different timestamps. We start off with a sketch and then just fill it out with interpolation.

    <p>
      <li>Inverse kinematics</li>
      We map the gripper plan sketch to moving the whole arm.
    </p>
  </ul>

  <subsection id="0.0"><h1>Basic strategy</h1>
    We have designed the gripper poses as a function of time using a trajectory generator and our aim is obtain corresponding joint positions as a function of time:

    $$
      X^G(t) \rightarrow q(t)
    $$

    The controller takes joint positions as input so we need to go from EE coordinates to joint commands. We start with a $q(0)$ and integrate forward using the joint velocity for that instant. The joint velocity is obtained by taking the inverse jacobian of the spatial velocity:

    $$
      \dot{q}(t) = [J^G(q)]^{-1}V^G(t)
    $$
    $V^G(t)$ is the spatial velocity of the gripper as a function of time.

    <p>
      We need to make sure the matrix is invertible or address it with more sophisticated methods. But intuitively we're going to design controllers that use the derivative of the kinematics (jacobian is approximately the derivative of FK) to get the smoothness in joint position transitions from one time instant to the next. 
    </p>

    We want to convert the smooth trajectory in EE coordinates to a smooth trajectory in the joint space, avoiding kinematic sigularities.
  </subsection>
</section>

<section id="1"><h1>Notations</h1>
  <subsection id="1.0"><h1>Position</h1>
    The simplest concept is just a point in some three-dimensional space. 
    <ul>
      <li>$A$ is the frame or point of interest</li>
      <li>$P^A$ - Position of $A$</li>
      <p>
        <li>$^BP^A$ - Position of $A$ relative to $B$</li>
        $P$ is a vector going from point $B$ to $A$ - Imagine an arrow drawn from $B$ to $A$. Positions always have to be defined w.r.t. something.
      </p>
      <li>$\in\mathbb{R}^3$</li>
      Our 3D vectors (3x1) contain 3 real numbers.
      <p>
        <li>$^BP^A_C$ - $C$ is the expressed in frame</li>
        Distance between 2 people is given by $P$. But if we turn our back, the vector between the 2 points is still the same, but now they'll be expressed using different numbers w.r.t. me looking the other way.
      </p>
    </ul>

    A <i>reference frame</i> has a point at its centre. Its orientation can be represented in many ways but it is visually represented with the xyz axes. XYZ => RGB. Use the <a href="https://bit.ly/3FdV8Sl">right-hand rule</a> (vehicle coordinate system). 

    <p>
      We'll have lots of frames. Our aim will be to get the frames to match; because once they do, the algebra becomes trivial. For example, once the frames match, we can add positions.

      <div class="container">
        <figure>
          <img style="height:60px; width:auto"
          src="../../../figures/manipulation/34_vectorAddition.png"/>
          <figcaption>
            $^BP^E_C = ^BP^A_C + ^AP^E_C$
          </figcaption>
        </figure>
      </div>
    </p>
    Another example, inverse flips the sign: $-^BP^A_C = ^AP^B_C$
  </subsection>

  <subsection id="1.1"><h1>Orientation</h1>
    There are a number of ways to represent the relative orientation: 
    <ul>
      <li>Rotation matrix</li>
      <li>Euler angles of which there are many but the familiar ones are roll pitch yaw</li>
      <li>Quaternions</li>
    </ul>
    There are functions that let us go back and forth in between them.  Unfortunately there's no one representation to rule them all. Different parts of the stack will use different representations. But in the spatial algebra we call the whole thing $R$. Orientation of $A$ relative to $B$:  
    $$^BR^A$$ 
    
    This orientation can be represented in any of the above formats, but we'll still call it $R$ for the actual purposes of the algebra. For orientations, we use the multiplication operator instead of the addition operator: 
    $$
      ^BR^A \cdot ^AR^C = ^BR^C
    $$

    Orientations don't need an expressed-in frame. We can turn our head however we want or change the current frame, but the rotation of $A$ relative to $B$ will still be the same. Just like we had an additive inverse for addition we have a multiplicative inverse for rotations/orientations:
    $$
      [^BR^A]^{-1} = ^AR^B
    $$ 

    If we think about $R$ as a rotation matrix, then the inverse is just the matrix inverse and life is good. We've abstracted away from the underlying numerical representation. We're just talking about the ability to go back and forth between rotations. It happens that if we have a 3x3 rotation matrix representing the orientation, then because rotation matrices are orthonormal, the transpose is the same as the inverse. 
  </subsection>

  <subsection id="1.2"><h1>Pose</h1>
    The position and orientation of a frame, put together, is called the <i>pose</i> of the frame:
    $$
      ^BX^A
    $$
    
    This is the position and orientation of frame $A$ relative to the position and orientation of frame $B$. In Drake, <n>pose is the noun and transform is the verb</n>. For the things we do in robotics, we do not need an expressed-in frame for a transform $^BX^A$. It's fine to put it in, but it's not needed. We however use the expressed-in frame for the derivative of a pose i.e. the spatial velocity $V_{6 \times 1}$.

    <p>
      $P^A$ is the same as $^WP^A_W$. In drake visualisations, an RGB axis at the origin defines the world axis. If the expressed-in frame is not specified, it should be assumed that:
      $$^GP^A \equiv {^GP^A_G}$$ 
    </p>

    $$\begin{align*}
      ^GP^A &= ^GX^F \cdot {^FP^A} \\
            &= (^GP^F \cdot {^GR^F}) \cdot {^FP^A} \\
            &= (^GP^F_G \cdot {^GR^F_G}) \cdot {^FP^A} \\
    \end{align*}$$

    If these were all expressed in different frames, then it would not be a valid equation. The multiplication operator along with the rotation that is encoded in $X$ transforms the position of $A$ in the following way:
    <ul>
      <li>W.r.t. $F$ to another frame, w.r.t. $G$</li>
      <li>The expressed-in frame, from $F$ to $G$</li>
      <n>The basic operation of a rotation matrix is to take a position and change its expressed-in frame</n>.
    </ul>
    
    A pose also has a multiplicative inverse:  $[^GX^F]^{-1} = {^FX^G}$. A pose can be represented in different ways. This is only a notation indicating we are taking an inverse. But actually it's not just a direct matrix inverse - <m>it will be some simple function of the elements of the matrix representation</m>. A lot of times a pose is represented as a 3x4 matrix for instance.

    <p>
       Pose can also be called a <i>rigid transform</i> because it only allows changing between frames in the kinematics, i.e. only positions and rotations; no scaling or shearing. <i>Homogeneous transforms</i> also allow shearing and scaling.
    </p>

    Poses multiply with other poses. A set of rules are given in Chapter 3.
  </subsection>

  <subsection id="1.3"><h1>Notation understanding check</h1>
    <div class="container">
      <figure>
        <img style="height:120px; width:auto"
        src="../../../figures/manipulation/38_poseQuestion.png"/>
        <figcaption>
          What is $^GP^O$ and $^GP^O_W$?
        </figcaption>
      </figure>
    </div>

    For the question above, the possible answers are: (a) [.2,0,-.2], (b) [0,.3,.1], (c) [0,-.3,.1]

    <p>
      $^GP^O = {^GR^W} \cdot {^WP^O}$
    </p>

    $^WP^O$ will undergo 2 rotations to align $W$ with $G$: <code>Rotz(-90), Rotx(-45)</code>. Once it's aligned, we can see there is an offset in the Y and Z directions. Hence the answer must be (b).

    <p>
      $^GP^O_W = {^WR^G} \cdot {^GP^O}$
    </p>

    This is the same as $^WP^O$. We can see there is an offset in the Z and X directions. Hence the answer must be (a).
  </subsection>
  
  <subsection id="1.4"><h1>Example usage</h1>
    The is core to planning, perception, controls etc. If we had cameras mounted around a kuka, taking some depth measurements, trying to find out where things are in the scene. The data coming into each of those cameras are going to be in the associated camera's frame. For it to be usable, we'll have to convert it to a common representation - a common coordinate frame typically a world frame (or a gripper frame). The way we do that is by multiplying each camera's output by $X$. We can put them together if the frames match. 

    <div class="container">
      <figure>
        <img style="height:50px; width:auto"
        src="../../../figures/manipulation/35_notationUsage.png"/>
        <figcaption>
          Notation usage example in multi-camera scenario
        </figcaption>
      </figure>
    </div>
  </subsection>
</section>

<section id="2"><h1>Frames for pick and place</h1>
  <table class="table1 center">
    <tr>
      <th>Object frames</th>
      <th>Gripper frames</th>
    </tr>
    <tr>
      <td>$O_{initial}$, $O_{goal}$</td>
      <td>$G_{initial}$, $G_{pick}$
        <br>
        $G_{prepick}$, $G_{postpick}$
        <br>
        $G_{place}$
        <br>
        $G_{preplace}$, $G_{postplace}$
        <br>
        $G_{clearance}$</td>
    </tr>
  </table>

  The numerical representation used to represent a frame, say $O_{initial}$ on disk is its pose -  $^WX^{O_{initial}}$. $O$ is an example of a frame which just defines the semantics of whether we can connect two poses. But the pose $X$ is the manifestation that holds the position and orientation of a frame relative to some other frame. $O$ in some sense is absolute and can't be represented because we have to somehow make a pose relative to something else.

  <p>
    Representing the pose of the object relative to the gripper or vice-versa is the most simple/robust representation commonly used for picking an object.
  </p>

  We interpolate from some initial gripper pose to a pose with the right clearance above the object to guarantee we avoid any collisions.Then we do a simpler approach to the object. People do lots of interesting complicated algorithms to figure out how to move through space and just hand code the last movement often to avoid collision. 

  <p>
    To define the position of the gripper to move into to pick an object, pick whatever direction (in terms of axis) is the easiest relative to the object. A similar thinking applies to orientation. For this, it would be good to know what orientation the object is in. For a little red cube, it is hard to get its orientation from a perception system because it's symmetric. Then we get our pose $^{G_{pick}}X^{O_{initial}}$. We do the same for pre/post pick etc.
  </p>

  In code, $^BX^A_C \equiv$ <code>X_BA_C</code>. ${^WX^A_W} = X^A \equiv$ <code>X_A</code>

  <subsection id="2.0"><h1>Timing between key frames</h1>
    Sometimes the time to finish a segment between going from 1 key frame to another, is absolute. Sometimes, it's scaled based on the distance between the frames. 
  </subsection>
</section>

<section id="3"><h1>Interpolation between poses</h1>
  We need to figure out where the gripper needs to be at all times between the pick and place frames, i.e. we need to interpolate between the key poses.

  <subsection id="3.0"><h1>Interpolation between positions</h1>
    <p>
      Say, we had the following plot:
      <ul>
        <li>X-axis: time.</li>
        We can specify when the pick and place should take place and all the other intermediate frames specified in time.

        <p>
          <li>Y-axis: ${^WP^G_{W_x}}$</li>
          The position of the gripper in the world frame is a 3 element vector but we only consider the x component.
        </p>
      </ul>
    </p>

    <div class="container">
      <figure>
        <img style="height:80px; width:auto"
        src="../../../figures/manipulation/39a_positionInterpolation.png"/>
        <figcaption>
          Key frames between pick and place times
        </figcaption>
      </figure>
      <figure>
        <img style="height:80px; width:auto"
        src="../../../figures/manipulation/39b_positionInterpolation.png"/>
        <figcaption>
          First order interpolation
        </figcaption>
      </figure>
      <figure>
        <img style="height:80px; width:auto"
        src="../../../figures/manipulation/39c_positionInterpolation.png"/>
        <figcaption>
          Zero order hold
        </figcaption>
      </figure>
    </div>

    There are different ways of interpolating:
    <ul>
      <li>First order hold</li>
      It's called first order because the line joining 2 points has 1DOF i.e. the slope of the line. It's a simple straight line interpolation. Doing a first order interpolation for orientation requires a bit more care compared to doing it for positions.

      <p>
        <li>Zero order hold</li>
        Zero order hold would be if there was no interpolation between the points and we just did some staircase. It is not safe to run this on a robot.
      </p>
      
      <li>Higher order interpolations</li>
      They give nice curves between key poses.
    </ul>
  </subsection>
  
  <subsection id="3.1"><h1>Problems faced when interpolating between orientations</h1>
    <subsubsection><h1>Choice of representation</h1>
      Some representations look simple to interpolate but then would blow up - could potentially go through bad states in the middle. 

      <p>
        There are roll pitch yaw values that represent very similar orientations but are actually very far in the values. Trying to go between one and another representation of roll pitch yaw might take the robot through extremely large numbers. This goes along with gimbal lock. 
      </p>
    </subsubsection>

    <subsubsection><h1>Simple linear interpolation for orientations is not possible</h1>
      Let's take a simple 2D rotation matrix example. We have a 2D rotation written as a function of some angle $\theta$ which will rotate a $2 \times 1$ vector by $\theta$ degrees:
      $$
        R(\theta) = \begin{bmatrix}
        c\theta & -s\theta \\
        s\theta & c\theta
        \end{bmatrix}
      $$

      Let's say we have 2 rotation matrices for rotating by $90^0$ and the other by $0^0$.
      $$
        R(0) = \begin{bmatrix}
        1 & 0 \\
        0 & 1
        \end{bmatrix} \quad
        R(\frac{\pi}{2}) = \begin{bmatrix}
        0 & -1 \\
        1 & 0
        \end{bmatrix}
      $$

      <div class="container">
        <figure>
          <img style="height:80px; width:auto"
          src="../../../figures/manipulation/40a_0rotation.png"/>
          <figcaption>
            Rotation of a unit frame <code>Rotz(0)</code>
          </figcaption>
        </figure>
        <figure>
          <img style="height:80px; width:auto"
          src="../../../figures/manipulation/40b_90rotation.png"/>
          <figcaption>
            Rotation of a unit frame <code>Rotz(90)</code>
          </figcaption>
        </figure>
      </div>
      If we were to linearly interpolate between the 2 angles, we wouldn't get $45^0$ i.e. we'd get $\frac{1}{2}$s in the rotation matrix instead of $\frac{1}{\sqrt{2}}$s. We can't just interpolate orientations.
    </subsubsection>

    <subsubsection><h1>Why don't we have such problems with angular velocities</h1>
      Angles wrap around every $2\pi$ and velocities don't. If we rotate by $\pi$, $-\pi$ or $3\pi$, we'll end up at the same place. But $100rad/s$ is still different than every other positive radian per second.

      <p>
        In 2D, you can represent everything with a scalar, a single rotation. When the wrapping effect is seen, flip back from polar coordinates or rectangular coordinates and we can always figure out the angles between two locations. In 2d, if we think about a rotation taking us around a unit sphere - a point moving around the unit sphere, the angular velocity is just the tangent on that and it's well behaved.
      </p>
 
      In 3d, there are rotations/angles that we can get to from many paths and picking a unique inverse of it is messy. 
    </subsubsection>
  </subsection>

  <subsection id="3.2"><h1>The right way to interpolate between orientations</h1>
    People typically use:
    <ul>
      <li>The quaternion representation to get around gimbal lock</li>
      <li><i>SLERP (Spherical linear interpolation)</i> to get a smooth first order interpolation</li>
    </ul>
  </subsection>

</section>

<section id="4"><h1>Forward kinematics problem</h1>
  <subsection id="4.0"><h1>Description</h1>
    $$
      X^B = f^B_{kin}(q)
    $$  

    In this mathematical equation (actual implementation in code is different):
    <br>
    $q$ is the vector of positions.
    <br>
    $X$ is the pose in the world.
    <br>
    $f_{kin}$ is the FK of the body.
    <br>
    $B$ stands for body.
    <br>
    $G$ stands for gripper if it was used instead of $B$.    
    
    <p>
      The mapping from joint angles to poses is called the <i>Forward Kinematics problem</i>. Looking at the 2D rotation matrix above:
      $$
        R(\theta) = \begin{bmatrix}
        c & -s \\
        s & c     
        \end{bmatrix}
      $$
    </p>

    If we have joint angle $\theta$ and we want to turn it into a rotation or a pose then it is almost always going to be a nonlinear map from the joint angles into the poses. The matrix above is maybe the simplest example of it.
  </subsection>

  <subsection id="4.1"><h1>Computing the pose of the EE using FK</h1>
    Given that we've set all the joint angles:
    <ul>
      <li>Compute pose of the EE relative to the wrist</li>
      We find the rotation matrix for the rotation joint which is just a relative pose.

      <p>
        <li>Chain it backwards all the way to the world coordinates</li>
      </p>
    </ul>

    The math is simple because each individual joint is just describing a small rotation matrix kind of operation on a relative transform from right before the robot's joint until right after the robot's joint. That's how robots are specified in robot description files as relative poses of each link - 6 numbers: x, y, z, roll, pitch, yaw. Joints are just operations that will make a transformation from the pre joint frame to the post-joint frame. 

  </subsection>

  <subsection id="4.2"><h1>Defining $q$</h1>
    <p>
      $q$ should be defined in such a way so as to be sufficient to tell us where all the attached bodies are in the world. In iiwa that's bolted down, all we need are 7 numbers of the different rotations of the different joints. But if we have a red brick on the table, we need enough something in $q$ to be able to eventually pull out the pose. 
    </p>

    In code, we define a $3\times 3$ rotation matrix for each joint based on the corresponding joint angle. We can then go through a series of frame transformations (through all the joints) to get the full kinematics. 
    <ul>
      <li>Iiwa</li>
      In iiwa, it's a $7\times 1$ vector of rotational joint angles representing the revolute joints. It's 7 because we choose to use quaternions in the coordinate representation to avoid gimbal locks and singularities.

      <p>
        <li>Allegro hand</li>
        It has 4 fingers with 4 links per finger. Total number of joint angles is 16. Plus, 7 numbers to configure its position in space. 
      </p>

      <li>Allegro hand picking up a brick</li>
      23 numbers for the hand and 7 for the brick. The kinematics problem then becomes going from the 30 numbers (representing q) to some pose of the brick and hand.
    </ul>
  </subsection>

  <subsection id="4.3"><h1>Drake implementation</h1>
    To compute the FK in drake, we need to specify the frames to get the pose of the desired frame relative to some other frame expressed in some other frame.

    <p>
      The context is taken as the argument instead of $q$ because the kinematics can be parameterized. If we were designing a robot and we wanted to optimise the length of a link for instance. Then we'd like the kinematics to also be a function of the link lengths or some other quantities. Hence, this is useful.
    </p>

    The <i>context</i> is just state + parameters + time; it's just the structure that wraps it. 

    <p>
      Very often, quaternions is used to represent the position/orientation and rotation matrix is used to represent the pose $X$.
    </p>
  </subsection>
</section>

<section id="5"><h1>Inverse kinematics</h1>
  We want to go from poses in the world to joint positions.
  $$
    q = (f^B)^{-1}(X^B)
  $$
  
  This is a nonlinear complicated function called <i>inverse kinematics</i>. It's not necessarily a unique mapping - there can be multiple $q$s that get the same pose in the world. There could also be no solutions. Going the other way is more straight forward.   
  
  <p>
    Sometimes we use the IK directly but oftentimes we do not because if our IK engine gives us slightly different answers for very similar poses, then it might involve crazy arm movements to achieve it. We want to send smooth commands to the robot so that it's not jumping around to different solutions. When we specify IK, we normally also specify additional requirements for continuity/smoothness/centering etc. An example: if we had enough DOF in an arm and there were multiple solutions for joint angles given a fixed pose for the hand, then the IK engine could ask for different joint angles (for the same hand pose) every 0.0001 seconds. That wouldn't be good. 
  </p>
</section>

<section id="6"><h1>Differential IK</h1>
  <subsection id="6.0"><h1>Description</h1>
    In order to encourage smoothness between joint angles instead of IK we use the differential form of the kinematics where we examine how an incremental change in $q$ makes an incremental change in the pose $X$. If we want to make a relatively small change in a certain direction to the current pose, we figure out the incremental change in $q$ we need to make. Differential IK isn't defined perfectly everywhere but partial derivatives exist everywhere. 

    $$\begin{align*}
      \underbrace{dX^B}_{\text{Incremental change} \atop \text{in pose}} &= 
      \frac{\partial{f^B}(q)}{\partial{q}}
      
      \underbrace{dq}_{\text{Incremental change} \atop \text{in joint angle}} \\

      \underbrace{V^B}_{\text{Spatial} \atop \text{velocity}} 
      &= \underbrace{J^B(q)}_{\text{Jacobian}} \quad \dot{q} \\

    \end{align*}$$ 

    The Jacobian is a function of the current joint angles. 
  </subsection>
  
  <subsection id="6.1"><h1>Spatial velocity</h1>
    In order to start thinking about differential quantities (like the Jacobian), we'll need to know the joint velocity ($\frac{dq}{dt}$) and some pose velocity.

    <p>
      Just like we have spatial algebra for positions and orientations, we have it for velocities called <i>spatial velocity</i> which has a translation component and an orientation component:

      $$\begin{bmatrix}
        \omega \\ v
      \end{bmatrix}$$

      $\omega$ is the <i>angular velocities</i>, a $3 \times 1$ vector 
      <br>
      $v$ is the <i>translational velocities</i>, a $3 \times 1$ vector 
      <br>
      Spatial velocity is a $6 \times 1$ vector 
    </p>

    In pose, there's no canonical choice. In orientation, for example, we have problems based on the chosen representation. That's why we constantly move between representations. However there is a canonical choice for angular velocity. It is 3 numbers which are the rotations around the major axes. This notion of angular velocity simplifies everything once we get to velocities and spatial accelerations. 
  </subsection>

  <subsection id="6.2"><h1>Geometric jacobian</h1>
    <p>
      Geometric jacobian is always a function of $q$. It is a position dependent matrix.
    </p>
    Purely in terms of <n>representation</n> of spatial velocity, we have a canonical choice. The problem is that because we have so many different choices for $q$ and $X$, we have many different possible Jacobians to determine how we're going to go from joint angles/velocities to some spatial velocity. 
    
    <p>
      A <i>geometric jacobian</i> takes joint velocities and maps that to spatial velocity vectors. It's not quite $\frac{\partial{f^B}(q)}{\partial q}$. It's this plus the change of coordinates into the spatial vectors. The analytic jacobian is the true partial derivative. But it's not recommended as much. There are cases where we might want that but almost always spatial velocities is recommended. 
    </p>

    Floating Allegro hand + brick: 30 numbers, 23 positions but only 22 velocities. For example, we'll have an extra term if we use the quaternion representation. But, this needs to turn into the $6 \times 1$ spatial velocity vector. So, there is a change of representation that takes place.
  </subsection>

  <subsection id="6.3"><h1>Joint velocity</h1>
     How do we represent $\dot{q}$? The joint position vector (because of say quaternion representation) is often bigger than the joint velocity vector. And the spatial joint velocity can only take 6 numbers. Joint velocities won't always directly equal $\frac{dq}{dt}$ because of the choice of representation. We can map between them though. 
  </subsection>

  <subsection id="6.4"><h1>Inverse Jacobian</h1>
    <subsubsection><h1>The problem</h1>
      $$
        \dot{q}_{\scriptscriptstyle{7 \times 1}} = 
        [J^B_{\scriptscriptstyle{6\times{7}}}(q)]^{-1} 
        V^B_{\scriptscriptstyle{6\times{1}}}
      $$
      The matrix dimensions are written for iiwa where there are 7 joints and hence 7 $\dot{q}$s. However, we can't take the inverse of a non-square matrix. Hence, this equation only represents what we would like to do conceptually.
    </subsubsection>

    <subsubsection><h1>Pseudo Inverse Jacobian</h1>
      $$\begin{equation}
        \label{eq:pseudoInverseJacobian}
        \dot{q} = [J^B(q)]^{\dagger}V^B
      \end{equation}$$
      We actually do a pseudo inverse. It has magical properties. It works (i.e. it's well-defined)even if the matrix isn't square. When things are not square, we could have infinitely many or no solutions. <code>pinv</code> does the right thing. 

      <p>
        In the infinitely many solutions case, it will pick the one that's minimum norm in the least squares norm. It'll find the smallest solution. In this case it'd be the smallest joint velocities that achieve the desired velocity. If there are no solutions then it doesn't just fail it actually does its best effort and tries to find $\dot{q}$ that is as close to matching the equality as possible. The pseudo inverse is awesome. It just outputs a matrix.
      </p>

    </subsubsection>
  </subsection>
</section>

<section id="7"><h1>The controller</h1>
  <div class="container">
    <figure>
      <img style="height:60px; width:auto"
      src="../../../figures/manipulation/41_pseudoInverseController.png"/>
      <figcaption>
        $\dot{q}^d$ is desired IIWA velocities, $V^{G^d}$ is desired spatial velocities.
      </figcaption>
    </figure>
  </div>

  To compute the desired velocities, the pseudo inverse controller (PIC) needs:
  <ul>
    <li>a model of the robot (inside the block)</li>
    <li>current positions of the robot $q$</li>
    We could use the commanded/desired or the measured position. The latter could be noisy so it's more stable to use the former.

    <p>
      If actual positions were used instead, even in simulation, we'd get a good solution but then in the <i>null space</i> (in the multiple solution dimension) the elbow will walk around a little. It's a subtlety of the way these things feedback with the numerical precision of the integrator.
    </p>

    <li>commanded desired spatial velocities $V^{G^d}$</li>
  </ul>

  PIC takes in commanded poses and outputs commanded joint positions (integrator included). The manipulation station takes in desired position commands (not velocities), so we need an integration step to turn desired velocities into position commands. The initial conditions of the integrator need to match that of the robot, else the robot will go to a very bad initial condition at time zero. 

  <p>
    The manipulation station outputs the actual/measured iiwa positions. The trajectory generator converts the planned sketch into a spatial velocity trajectory. It feed into the PIC, which feeds into the integrator which feeds the manipualtion station.
  </p>

  <subsection id="7.0"><h1>Limitations</h1>
    The chapter's notebook has sliders that rotates the joints of the arm which then changes the Jacobian, which is printed.

    <p>
      If there are no solutions, the controller will come up with the best possible solution. It will find the minimum norm. When is it not enough? At a singularity. What does a singularity mean? 
    </p>

    <button class="accordion">Matrix rank</button>
    <div class="panel">
      <p></p>
      The <i>rank of a matrix</i> is the maximum number of linearly independent rows or columns in that matrix. In robotics, the <i>rank of a matrix</i> is used to determine the <i>manipulability</i> or <i>controllability</i> of a robot arm. It indicates the number of independent directions in which the end-effector of the arm can move. The <i>rank of the Jacobian matrix</i>, which relates the joint velocities to the end-effector velocities, provides valuable information about the arm's mobility and its ability to reach different positions and orientations in its workspace.

      <p>
        If the rank of the Jacobian matrix is equal to the number of DOF of the robot arm, it means that the arm can move freely in all possible directions within its workspace. This implies that the robot arm is fully controllable and can reach any desired position and orientation within its reachable workspace.
      </p>
      
      On the other hand, if the rank of the Jacobian matrix is less than the number of DOF, it suggests that the arm is kinematically constrained. This can occur when certain joints of the arm are mechanically linked or when there are other physical limitations that restrict the arm's movement. In such cases, the arm may have limited mobility and may not be able to reach all desired positions and orientations in its workspace.

      <p>
        In summary, the rank of a matrix, particularly the Jacobian matrix, provides insight into the controllability and mobility of a robot arm. A higher rank indicates greater freedom of movement, while a lower rank suggests constraints or limitations on the arm's motion.
      </p>
    </div>

    When the arm changes from having good solutions to having no or infinite solutions, there is the possibility of the rank of the matrix $[J^B(q)]^{-1}_{\scriptscriptstyle{6\times{7}}}$ to drop. Since we are trying to find $q$, we only care about the row rank. It is a good case, when we have 7 $\dot{q}$s and only 6 desired velocities, since we have multiple solutions. We never want the rank to drop below 6.

    <p>
      A robot will break before it drops rank. What actually happens is, as the robot approaches losing rank the inverse gets poorly conditioned and we'll get very big commanded velocities out which will cause the robot to hit a joint or velocity limit and it'll shut down.
    </p>

    The relative distance (numerically) between the smallest and largest singular value is not what matters. If the smallest singular value gets close to 0, we'd get large velocities on inverting the matrix. So it's useful to plot the smallest singular value. 
    
    <p>
      One easy way to get the arm in a singular state is to straighten it. There could be other singularities. When an arm is pretty extended and we try to extend it more, things are going to get bad.
    </p>

  </subsection>
</section>

<section id="8"><h1>Singularities</h1>
  Refer to <code>two_link_singularities.py</code>. It's a simple example of a two-link pendulum. It runs through a simple trajectory where it will get fully extended along the way. The pendulum is walking in and out of singularity with no problems. There's nothing blowing up but the Jacobian does go singular.

  <p>
    People talk a lot about singularities and they can be mysterious, but they need not be. We can derive the Jacobian for the example. Are there good solutions the controller could make or is it just hopeless?  We start by deriving the short version of the kinematics. 
  </p>

  <div class="container">
    <figure>
      <img style="height:80px; width:auto"
      src="../../../figures/manipulation/43_singularityExample2Link.png"/>
      <figcaption>
        2 link pendulum. $\theta_1$ will be negative since right-hand coordinate system is used.
      </figcaption>
    </figure>
  </div>

  The pendulum follows a simple open loop trajectory. It's designed so that the horizontal position of the EE is a sine wave and the vertical position (y axis) is always 0:

  $$
    P^G(t) = \begin{bmatrix}
      2c(1-t) \\
      0       \\
    \end{bmatrix}
  $$

  The position of the gripper is given by:
  $$
    P^G = \begin{bmatrix}
      c\theta_1 + c(\theta_1 + \theta_2) \\
      s\theta_1 + s(\theta_1 + \theta_2) \\
    \end{bmatrix}
  $$

  The first row is the x component. The first part of the first row is the contribution of link 1 and after the plus sign is the contribution of link 2. Taking the Jacobian is relatively simple. Here, in translational coordinates, there is no change of variables; no weird orientations; it really is just the partial derivative of this matrix.

  $$
    J^G = \begin{bmatrix}
      -s\theta_1 - s(\theta_1 + \theta_2) & -s(\theta_1 + \theta_2) \\
       c\theta_1 + c(\theta_1 + \theta_2) & c(\theta_1 + \theta_2)  \\
    \end{bmatrix}
  $$

  When the arm is fully extended, the sine of both angles go to 0 (in row 1) and the whole row goes to zero; The matrix drops rank.

  <p>
    Things could get bad with a pseudo inverse controller, but the aim is to understand why/how they get bad and how we can predict it. So singularities are real. It really is that the mapping between the EE positions and the joint angles gets into a terrible situation. But it does not mean the robot is helpless. So what does it mean?
  </p>

  If the arm is stretched out (in the forward direction), how do we control it to move it back (like in the <a href="https://shorturl.at/ghrW0">animation</a>)? Is there any velocity that we can command at the joint angles? If we have a desired velocity at the EE, how do we map to a desired velocity of the joints? We can't! The only possible velocity at the joints is zero. That's real, we can't move with a velocity instantaneously but we can accelerate backwards. By choosing a joint angle that is not instantaneously achieving the velocity objective, we can move out, start accelerating and get to a position where we can start commanding velocities. 

  <p>
    So thinking about things only in the EE velocity space does have foibles, some quirks but it does not mean the robot is helpless. It just means we have to be a little more clever. 
  </p>

  Q: If we move everything up to acceleration space have we just deferred the problem to the next set of variables? No. It's actually better in acceleration space. Now we'd have to think about exactly what the acceleration based controller would be to give a great answer. We can accelerate instantaneously but we cannot command a velocity instantaneously.

  <p>
    In practice, the thing to worry about is running the Jacobian based controller very close to dropping rank (similar to the pendulum example with the sine of angle being 0) because maybe we don't actually want the robot to be at its very end. But if we're just innocently choosing some trajectories we can get close to singularity (0) and we might start commanding ridiculous velocities ($\dot q$ is the output of the pseudo inverse (\ref{eq:pseudoInverseJacobian})). Even worse, the robot will be velocity limited and that velocity cap method will not be aware of the overall control objectives. There's a downstream part of the robot that might clip a joint's velocity even if a higher velocity was commanded. And it's not going to clip it nicely. It's just going to saturate or get into a fault.
  </p>

  So our solutions start getting arbitrarily wrong or we've commanded something bad. The pseudo inverse is a beautiful mathematical object. If we want to do our best effort knowing that there are limitations of the robot like velocity/joint limits and other things, the pseudo inverse doesn't have a chance if we haven't given it these extra bits of information. So we need a richer version of the pseudo-inverse that can consume more information about the problem specification. 

  <p>
    Q: If we have a singularity, aren't we also going to struggle to compute a torque? 
    $$
      \tau = J^{-1}(q)f
    $$

    Yes. Any jacobian-based approach is going to struggle. Is it true that we can't compute a torque for an arbitrary force? We can't produce a force instantaneously, but we can accelerate our joints in such a way, producing zero force that gets us out of the singularity. That is absolutely true but it's the differential version that gets us out. Just like it's bad to command velocities for an arm stretched out, it's also bad to ask for forces. That is just real - you cannot instantaneously produce a force.
  </p>
</section>

<section id="9"><h1>Differential IK as optimisation</h1>
  The Pseudo-Inverse controller is magical in the first place because it is solving an optimization problem. And we're going to solve harder optimization problems. But we'll try to understand the controller first through the lens of optimisation, then we can add in some constraints to have a more general solution. 

  <p>
    Find $\dot{q}$, such that the LHS is approximately equal (as close as possible) to the RHS (spatial velocity):
    $$
      J^G(q)\dot{q} \approx V^G
    $$
  </p>

  We're going to minimise over $\dot{q}$ the least squares error:
  $$
      \| J^G(q)\dot{q} - V^G\|^2
  $$

  <subsection id="9.0"><h1>Simple linear example - scalar case</h1>
    The above operation is standard in linear algebra. When people write $Ax\approx b$, they want to find the best solution for $x$ such that the LHS is approximately equal to the RHS.

    <div class="container">
      <figure>
        <img style="height:80px; width:auto"
        src="../../../figures/manipulation/50_leastSquares.png"/>
        <figcaption>
          $Ax \approx{b}$
        </figcaption>
      </figure>
    </div>

    There's only a few things that $a$, $x$ and $b$ can do. $a$ is the slope. $x^*$ is the solution we're looking for such that $ax^* = b$.

    <div class="container">
      <figure>
        <img style="height:80px; width:auto"
        src="../../../figures/manipulation/51_leastSquaresParabola.png"/>
        <figcaption>
          The quadratic curve of least squares.
        </figcaption>
      </figure>
    </div>
    $\|ax-b\|^2$ indicates that we're going to score all the different options along the parabola, the quadratic form to find the lowest point on the curve. When the curve touches 0, $ax=b$. The 2 values diverge, as the curve moves farther from 0.

    If the slope $a$ starts getting small, the solutions start getting worse! We need a bigger $x$ to achieve the same $b$. 

    <p>
      As the dimensions increase, we'd still like to be able to say how good any given solution is, even when the method isn't able to achieve the perfect solution. We want to be able to add constraints - the solution isn't allowed to go past a certain $x$ i.e. pick the smallest point on the curve that's within a certain regime. That's a richer class of optimizations but it's still based on the fundamental idea of first scoring all the points (on the parabola) and then finding the minimum of it. 
    </p>

    An example of this formulation would be:
    $$
      min_x \quad s.t. x\leq 2 \quad \|ax-b\|^2
    $$

    This equation says minimise over $x$ subject to $x$ is less than or equal to 2 (the boundary of the search, the regime, the stop condition). This would be a reasonable generalization of that optimization and it's a well-defined optimisation.

    <ul>
      <li>We've made a scoring function for all the possible $x$s</li>
      <li>We're limiting the search to the constraint $x \leq{2}$</li>
      <li>We find the lowest point</li>
    </ul>

    This is a more robust formulation because we're able to put more information into it. 
  </subsection>

  <subsection id="9.1"><h1>Simple linear example - vector/matrix case</h1>
    $$
      Ax \approx b
    $$
    The matrix case is only a little bit more interesting but super powerful.When things are unconstrained, the way we do the minimisation is to take the cost function (the quadratic $\|Ax-b\|^2$) and find the place where the gradient is the minimum. Since we know this is a convex bowl (with the ends) pointing up, it's enough to find any point where the gradient is zero:

    $$\begin{align*}
      \frac{\partial}{\partial x} \|Ax-b\|^2 &=
      \frac{\partial}{\partial x} [x^T A^T Ax - b^T Ax - x^T A^T b + b^2] \\
      &= 2x^T A^T A - 2b^T A = 0 \\
      (x^*)^T &= b^T \underbrace{A (A^T A)^{-1}}_{\text{Transpose of the} \atop \text{pseudo-Inverse}} \\

      x^* &= A^{\dagger}b
    \end{align*}$$

    $A (A^T A)^{-1}$ has no $b$ in it. That's why to take the pinv, we don't need to know $b$ to use it; because the solution is linear in $b$, we can separate out $A$ and $b$. It is kept in the form of the transposes for convenience.

    <div class="container">
      <figure>
        <img style="height:80px; width:auto"
        src="../../../figures/manipulation/52_quadraticBowl.png"/>
        <figcaption>
          The generalisation of the above parabola is a quadratic bowl.
        </figcaption>
      </figure>
    </div>

    In higher dimensions, the parabola turns into a quadratic bowl. The axes are $x_1$, $x_2$ and the objective $\|Ax-b\|^2$. We score every value $x$ by the cost function $\|Ax-b\|^2$ and find the minimum of it. As shown above, the quadratic form is given by: $[x^T A^T Ax - b^T Ax - x^T A^T b + b^2]$ but the shape is given by $A^T A$ in $x^T A^T Ax$.

    <p>
      When $A$ starts having small singular values, the bowl starts elongating just as in the case of the parabola with smaller slopes. It can elongate more or less in some directions/dimensions. As it gets long, the minimum $x$ starts leaving it, i.e. gets bigger. 
    </p>
  </subsection>

  <subsection id="9.2"><h1>Adding limits/boundaries</h1>
    If we add boundaries to the problem i.e. don't go past some reasonable velocities (some linear constraints), but within those bounded solutions, find the best solution using the score function $\|Ax-b\|^2$. This not the only generalization but this is the one that is used in the lectures.

    $$
    \|Ax-b\|^2 \quad s.t. \; \underbrace{Cx = d}_{\text{Linear constraint}}
    $$

    <div class="container">
      <figure>
        <img style="height:80px; width:auto"
        src="../../../figures/manipulation/53_boundaries.png"/>
        <figcaption>
          The generalisation, but with boundaries.
        </figcaption>
      </figure>
    </div>

    A problem like this that has a convex quadratic objective (we know that this bowl is going up) and linear constraints is called a <i>convex quadratic program</i>. It's an important class of optimization problems. Quadratic programs are not something we think of solving with pen and paper unless they're very very small. There are very efficient algorithms for finding them that can be run in real time at high speeds.

  </subsection>
</section>

<section id="10"><h1>Summary of the usefulness of optimisation</h1>
  To get more robust Jacobian based controllers, we need to use a richer language (i.e. give it more details of the robot). For example, we say, find the desired spatial velocity that is as close as possible to the minimum but respects the joint/acceleration/velocity limits of the robot. 

  <p>
    The 3 main pieces of drake:
    <ul>
      <li>The systems framework</li>
      <li>The multibody plant</li>
      <li>Mathematical programs</li>
    </ul>

    Mathematical programs make it really easy to write optimisation problems and connect it to the other two pieces. Drake is a language that provides this framework - we can say I'm going to make a new optimization problem or a mathematical program. <i>Mathematical programs</i> are slightly bigger than optimisation. It doesn't need to have an objective. If it's a feasibility problem with no objective you can study mathematically. 
    
  </p>

  For an optimisation problem, in drake, we can:
  <ul>
    <li>Declare the decision variables $x$</li>
    <li>Add constraints</li>
    <li>Add cost function</li>
    <li>Solve to get the solution as the output</li>
  </ul> 
</section>

<section id="11"><h1>Example</h1>
  In <code>qp_diff_ik.ipynb</code>, the Kuka is turned into a 2d version. Only 2 joints are active to make it as similar as possible to the 2 link pendulum example. It plots the quadratic cost function in the 2 variables (in green) which is the optimization problem given by the Jacobian $\|J^{G}(q) \dot{q}-V^G\|^2$ subject to a few constraints on velocities. The constraints are in red. The optimal solution is represented by a green blob. 

  <p>
    The arm moves back and forth through the singularity. When the arm is straight, the bowl goes completely flat (if our viewing angle is set correctly, we can see it). It goes flat depending on how quickly the code integrates, but it gets broader and broader. Already in this configuration, the solution looks a little dicey up against the velocity limit. The arm has a tilt to it too, so the optimal solution would have been a very large velocity but the constraints keep us safe. 
  </p>
</section>

<section id="12"><h1>Closing remarks</h1>
  Q: What if the actual constraints are not linear? We can choose to solve a harder optimisation problem but the standard choice is linear. For instance the joint limits actually would be a nonlinear function in general. But we approximate it with an euler approximation which makes it a linear constraint. Position and acceleration limits are actually linear for any euler kind of integration step. Torque limits are not linear. The linearization for the latter is a bit tricky but we tend to not do torque limits. 

  <p>
    The idea of optimisation and quadratic programming is such a powerful framework and we're going to use it more. This is just a quick introduction. 
  </p>

  The worst case is when the robot is up against a limit on one joint. For instance, the second joint moves along as if nothing happened and the first joint changes which means the hand is going off in the wrong direction. We're going to eventually have feedback loops coming through this whole system and that's what's going to save us. But even in this open loop framework because we know about where the limits are, we can plan for them without any direct feedback and we can at least do a better best effort in the beginning. 

  <p>
    For instance, the way that we actually run the robot is we don't run it to be as close as possible to our desired velocity in the least squares sense. We actually do a slightly different objective. We have some desired velocity. We pick joint angles that will move the hand in the direction of that velocity. When a limit is hit we scale down the whole velocity but keep the direction the same; because we don't want our robot walking away from the desired trajectory. This is a richer formulation but we can still make it work as a quadratic program. 
  </p>

  <subsection id="12.0"><h1>QP formulation 1</h1>
    Find $\dot{q}$ such that $J^G(q)\dot{q} \approx V^G$.

    $$\begin{align*}
      min_{\dot{q}} \quad &\|J^G(q)\dot{q} - V^G\|^2 \\
      s.t. \quad & \|\dot{q}\| \leq \dot{q}_{max} \\
          & \text{joint/acceleration limits etc.}
    \end{align*}$$
  </subsection>

  <subsection id="12.1"><h1>QP formulation 2</h1>
    This is a slightly different formulation which says constrain the arm to move only in the desired direction of the gripper. We're going to maximise a linear objective. This is actually a simpler program.

    $$\begin{align*}
      max_{\dot{q}, \alpha} \; & \alpha \\
      s.t. \quad & J^G(q)\dot{q} = \alpha V^G \\
          & 0 \leq \alpha \leq 1 \\
          & \text{joint velocity/acceleration/position limits}
    \end{align*}$$

    $\dot{q}$ (vector), $\alpha$ (scalar) are the decision variables. The objective though is only in terms of one of the decision variables; the aim is to make the scalar $\alpha$ as big as possible (maximise) subject to the above conditions. The desired spatial velocity is a vector which is allowed to be scaled by $\alpha$, but we must choose a $\dot{q}$ on the LHS that matches some scaled version of that vector. 

    <p>
      Even though $\dot{q}$ is not part of the objective, we still need to define a solution for it because it enters in via the equality constraint. So $\dot{q}$ can only live on the set of possible $\dot{q}$s such that $\dot{q}$ times the current Jacobian (LHS) moves the EE in the direction of the desired spatial velocity (RHS)! If $\alpha$ is arbitrary, then if we have one $\dot{q}$ that's a solution, we could multiply it by two and it would still be a solution. 
    </p>

    So basically, we take the $\dot{q}$ that will achieve the objective without any constraints and then scale it down - shrink all of the joint velocities by the same scaling in order to satisfy the constraints. So now the arm will always move in the desired direction - it would rather stop completely when deviating.

    <p>
      This is what's happening inside the differential IK. This differential IK controller was used in the first teleop notebook. One will get a lot of mileage out of this method in the class. It takes in poses, does the differentiation and integration and runs this kind of control. 
    </p>
  </subsection>

  <subsection id="12.2"><h1>Comparison of the 2 formulations</h1>
    Between the 2 methods, we only changed what we want as a degradation in performance. When we have to give up performance, we can choose what we give up. In the 1st case we are after a spatial velocity as output that's as close as possible in the least squares sense to the desired spatial velocity. In the 2nd case we are willing for it to be less close in the numbers as long as it stays constrained in the right direction. So it's just a different choice of how we are okay for it to degrade when it can't satisfy the constraints perfectly. 

    <p>
      What happens if there were no constraints? In the 2nd case, it's going to choose $\alpha = 1$ and it's going to make $\dot{q}$ exactly equal to the spatial velocity. So it'll solve the problem exactly. And as the constraints become active because the arm might be running up against them, then $\alpha$ will have to shrink and that can be considered as a very graceful degradation.
    </p>

    In the 1st case if there are no limits, again it'll find $\dot{q}$ exactly to drive the objective to zero. As the constraints come on, it will find a different velocity but it might make the arm move in the wrong direction. We get to specify how we want it to degrade. 
  </subsection>

</section>
</details>
</chapter>

</body>
</html>
