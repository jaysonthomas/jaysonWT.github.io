
<!DOCTYPE html>
<html>
<head>
  <title>Basics of pick and place</title>
  <meta name="Basics of pick and place" content="text/html; charset=utf-8;" />
  <script type="text/javascript" src="../../../logbook.js"></script>

  <script src="../../../logbook-mathjax-config.js" defer></script> 
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/atom-one-light.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <link rel="stylesheet" type="text/css" href="../../../logbook.css" />
</head>

<body onload="loadChapter('');">  

  <div data-type="titlepage" pdf="no">
    <header>
      <h1><a href="../../../index.html" style="text-decoration:none;">Logbook</a></h1>
      <p style="font-size: 18px;"><a href="../../../bio/jjwt.html">Jayson Wynne-Thomas</a></p>
      <p style="font-size: 14px; text-align: right;"> 
        Last modified <span id="last_modified"></span>.</br>
        <script>
        var d = new Date(document.lastModified);
        document.getElementById("last_modified").innerHTML = d.getFullYear() + "-" + (d.getMonth()+1) + "-" + d.getDate();</script>
      </p>
    </header>
  </div>

  <table style="width:100%;" pdf="no"><tr style="width:100%">
    <td style="width:33%;text-align:left;">
      <a class="previous_chapter" href="">Prev Chapter</a>
    </td>
    
    <td style="width:33%;text-align:center;">
      <a href="">Root Chapter</a>
    </td>
    
    <td style="width:33%;text-align:right;">
      <a class="next_chapter" href="">Next Chapter</a>
    </td>
  </tr></table>
  
  <div id="main" class="sidebar1">
    <span style="font-size:10px;cursor:pointer" onclick="openNav()">&#9776;</span>
  </div>

  <div id="mySidenav" class="sidebar">
  
<a href="#0">Overview</a>
<ul class="no-bullets">
  <li><a href="#0.0">Basic strategy</a></li>
</ul>
<a href="#1">Notations</a>
<ul class="no-bullets">
  <li><a href="#1.0">Position</a></li>
  <li><a href="#1.1">Orientation</a></li>
  <li><a href="#1.2">Pose</a></li>
  <li><a href="#1.3">Notation understanding check</a></li>
  <li><a href="#1.4">Example usage</a></li>
</ul>
<a href="#2">Frames for pick and place</a>
<ul class="no-bullets">
  <li><a href="#2.0">Timing between key frames</a></li>
</ul>
<a href="#3">Interpolation between poses</a>
<ul class="no-bullets">
  <li><a href="#3.0">Interpolation between positions</a></li>
  <li><a href="#3.1">Problems faced when interpolating between orientations</a></li>
  <li><a href="#3.2">The right way to interpolate between orientations</a></li>
</ul>
<a href="#4">Forward kinematics problem</a>
<ul class="no-bullets">
  <li><a href="#4.0">Description</a></li>
  <li><a href="#4.1">Computing the pose of the EE using FK</a></li>
  <li><a href="#4.2">Defining $q$</a></li>
  <li><a href="#4.3">Drake implementation</a></li>
</ul>
<a href="#5">Inverse kinematics</a>
<a href="#6">Differential IK</a>
<ul class="no-bullets">
  <li><a href="#6.0">Description</a></li>
  <li><a href="#6.1">Spatial velocity</a></li>
  <li><a href="#6.2">Geometric jacobian</a></li>
  <li><a href="#6.3">Joint velocity</a></li>
  <li><a href="#6.4">Inverse Jacobian</a></li>
</ul>
<a href="#7">The controller</a>
<ul class="no-bullets">
  <li><a href="#7.0">Limitations</a></li>
</ul>
</div>

<chapter style="counter-reset: chapter 3"><h1>Basics of pick and place</h1>

<section id="0"><h1>Overview</h1>
  <ul>
    <li>Getting the notations right</li>
    Even in deep neural networks (say to calculate pose estimation), we're going to have a kinematics problem at some point and we're going to have a bug where the vectors are pointing the wrong way etc. If we get the notations right, spatial algebra will protect us.

    <p>
      <li>Choosing our frames</li>
      We have a gripper and a gripper frame; an object and an object frame. To grasp, we need to get the gripper frame in the right relative orientation and position to the object frame. 
    </p>

    <li>Trajectory generation</li>
    We'll plot the frames for the open-loop trajectory of the gripper picking up and dropping off the brick at the desired location. We forget the rest of the robot and just decide the different trajectory of poses the hand needs to go through in space at different timestamps. We start off with a sketch and then just fill it out with interpolation.

    <p>
      <li>Inverse kinematics</li>
      We map the gripper plan sketch to moving the whole arm.
    </p>
  </ul>

  <subsection id="0.0"><h1>Basic strategy</h1>
    We have designed the gripper poses as a function of time using a trajectory generator and our aim is obtain corresponding joint positions as a function of time:

    $$
      X^G(t) \rightarrow q(t)
    $$

    The controller takes joint positions as input so we need to go from EE coordinates to joint commands. We start with a $q(0)$ and integrate forward using the joint velocity for that instant. The joint velocity is obtained by taking the inverse jacobian of the spatial velocity:

    $$
      \dot{q}(t) = [J^G(q)]^{-1}V^G(t)
    $$
    $V^G(t)$ is the spatial velocity of the gripper as a function of time.

    <p>
      We need to make sure the matrix is invertible or address it with more sophisticated methods. But intuitively we're going to design controllers that use the derivative of the kinematics (jacobian is approximately the derivative of FK) to get the smoothness in joint position transitions from one time instant to the next. 
    </p>

    We want to convert the smooth trajectory in EE coordinates to a smooth trajectory in the joint space, avoiding kinematic sigularities.
  </subsection>
</section>

<section id="1"><h1>Notations</h1>
  <subsection id="1.0"><h1>Position</h1>
    The simplest concept is just a point in some three-dimensional space. 
    <ul>
      <li>$A$ is the frame or point of interest</li>
      <li>$P^A$ - Position of $A$</li>
      <p>
        <li>$^BP^A$ - Position of $A$ relative to $B$</li>
        $P$ is a vector going from point $B$ to $A$ - Imagine an arrow drawn from $B$ to $A$. Positions always have to be defined w.r.t. something.
      </p>
      <li>$\in\mathbb{R}^3$</li>
      Our 3D vectors (3x1) contain 3 real numbers.
      <p>
        <li>$^BP^A_C$ - $C$ is the expressed in frame</li>
        Distance between 2 people is given by $P$. But if we turn our back, the vector between the 2 points is still the same, but now they'll be expressed using different numbers w.r.t. me looking the other way.
      </p>
    </ul>

    A <i>reference frame</i> has a point at its centre. Its orientation can be represented in many ways but it is visually represented with the xyz axes. XYZ => RGB. Use the <a href="https://bit.ly/3FdV8Sl">right-hand rule</a> (vehicle coordinate system). 

    <p>
      We'll have lots of frames. Our aim will be to get the frames to match; because once they do, the algebra becomes trivial. For example, once the frames match, we can add positions.

      <div class="container">
        <figure>
          <img style="height:60px; width:auto"
          src="../../../figures/manipulation/34_vectorAddition.png"/>
          <figcaption>
            $^BP^E_C = ^BP^A_C + ^AP^E_C$
          </figcaption>
        </figure>
      </div>
    </p>
    Another example, inverse flips the sign: $-^BP^A_C = ^AP^B_C$
  </subsection>

  <subsection id="1.1"><h1>Orientation</h1>
    There are a number of ways to represent the relative orientation: 
    <ul>
      <li>Rotation matrix</li>
      <li>Euler angles of which there are many but the familiar ones are roll pitch yaw</li>
      <li>Quaternions</li>
    </ul>
    There are functions that let us go back and forth in between them.  Unfortunately there's no one representation to rule them all. Different parts of the stack will use different representations. But in the spatial algebra we call the whole thing $R$. Orientation of $A$ relative to $B$:  
    $$^BR^A$$ 
    
    This orientation can be represented in any of the above formats, but we'll still call it $R$ for the actual purposes of the algebra. For orientations, we use the multiplication operator instead of the addition operator: 
    $$
      ^BR^A \cdot ^AR^C = ^BR^C
    $$

    Orientations don't need an expressed-in frame. We can turn our head however we want or change the current frame, but the rotation of $A$ relative to $B$ will still be the same. Just like we had an additive inverse for addition we have a multiplicative inverse for rotations/orientations:
    $$
      [^BR^A]^{-1} = ^AR^B
    $$ 

    If we think about $R$ as a rotation matrix, then the inverse is just the matrix inverse and life is good. We've abstracted away from the underlying numerical representation. We're just talking about the ability to go back and forth between rotations. It happens that if we have a 3x3 rotation matrix representing the orientation, then because rotation matrices are orthonormal, the transpose is the same as the inverse. 
  </subsection>

  <subsection id="1.2"><h1>Pose</h1>
    The position and orientation of a frame, put together, is called the <i>pose</i> of the frame:
    $$
      ^BX^A
    $$
    
    This is the position and orientation of frame $A$ relative to the position and orientation of frame $B$. In Drake, <n>pose is the noun and transform is the verb</n>. For the things we do in robotics, we do not need an expressed-in frame for a transform $^BX^A$. It's fine to put it in, but it's not needed. We however use the expressed-in frame for the derivative of a pose i.e. the spatial velocity $V_{6 \times 1}$.

    <p>
      $P^A$ is the same as $^WP^A_W$. In drake visualisations, an RGB axis at the origin defines the world axis. If the expressed-in frame is not specified, it should be assumed that:
      $$^GP^A \equiv {^GP^A_G}$$ 
    </p>

    $$\begin{align*}
      ^GP^A &= ^GX^F \cdot {^FP^A} \\
            &= (^GP^F \cdot {^GR^F}) \cdot {^FP^A} \\
            &= (^GP^F_G \cdot {^GR^F_G}) \cdot {^FP^A} \\
    \end{align*}$$

    If these were all expressed in different frames, then it would not be a valid equation. The multiplication operator along with the rotation that is encoded in $X$ transforms the position of $A$ in the following way:
    <ul>
      <li>W.r.t. $F$ to another frame, w.r.t. $G$</li>
      <li>The expressed-in frame, from $F$ to $G$</li>
      <n>The basic operation of a rotation matrix is to take a position and change its expressed-in frame</n>.
    </ul>
    
    A pose also has a multiplicative inverse:  $[^GX^F]^{-1} = {^FX^G}$. A pose can be represented in different ways. This is only a notation indicating we are taking an inverse. But actually it's not just a direct matrix inverse - <m>it will be some simple function of the elements of the matrix representation</m>. A lot of times a pose is represented as a 3x4 matrix for instance.

    <p>
       Pose can also be called a <i>rigid transform</i> because it only allows changing between frames in the kinematics, i.e. only positions and rotations; no scaling or shearing. <i>Homogeneous transforms</i> also allow shearing and scaling.
    </p>

    Poses multiply with other poses. A set of rules are given in Chapter 3.
  </subsection>

  <subsection id="1.3"><h1>Notation understanding check</h1>
    <div class="container">
      <figure>
        <img style="height:120px; width:auto"
        src="../../../figures/manipulation/38_poseQuestion.png"/>
        <figcaption>
          What is $^GP^O$ and $^GP^O_W$?
        </figcaption>
      </figure>
    </div>

    For the question above, the possible answers are: (a) [.2,0,-.2], (b) [0,.3,.1], (c) [0,-.3,.1]

    <p>
      $^GP^O = {^GR^W} \cdot {^WP^O}$
    </p>

    $^WP^O$ will undergo 2 rotations to align $W$ with $G$: <code>Rotz(-90), Rotx(-45)</code>. Once it's aligned, we can see there is an offset in the Y and Z directions. Hence the answer must be (b).

    <p>
      $^GP^O_W = {^WR^G} \cdot {^GP^O}$
    </p>

    This is the same as $^WP^O$. We can see there is an offset in the Z and X directions. Hence the answer must be (a).
  </subsection>
  
  <subsection id="1.4"><h1>Example usage</h1>
    The is core to planning, perception, controls etc. If we had cameras mounted around a kuka, taking some depth measurements, trying to find out where things are in the scene. The data coming into each of those cameras are going to be in the associated camera's frame. For it to be usable, we'll have to convert it to a common representation - a common coordinate frame typically a world frame (or a gripper frame). The way we do that is by multiplying each camera's output by $X$. We can put them together if the frames match. 

    <div class="container">
      <figure>
        <img style="height:50px; width:auto"
        src="../../../figures/manipulation/35_notationUsage.png"/>
        <figcaption>
          Notation usage example in multi-camera scenario
        </figcaption>
      </figure>
    </div>
  </subsection>
</section>

<section id="2"><h1>Frames for pick and place</h1>
  <table class="table1 center">
    <tr>
      <th>Object frames</th>
      <th>Gripper frames</th>
    </tr>
    <tr>
      <td>$O_{initial}$, $O_{goal}$</td>
      <td>$G_{initial}$, $G_{pick}$
        <br>
        $G_{prepick}$, $G_{postpick}$
        <br>
        $G_{place}$
        <br>
        $G_{preplace}$, $G_{postplace}$
        <br>
        $G_{clearance}$</td>
    </tr>
  </table>

  The numerical representation used to represent a frame, say $O_{initial}$ on disk is its pose -  $^WX^{O_{initial}}$. $O$ is an example of a frame which just defines the semantics of whether we can connect two poses. But the pose $X$ is the manifestation that holds the position and orientation of a frame relative to some other frame. $O$ in some sense is absolute and can't be represented because we have to somehow make a pose relative to something else.

  <p>
    Representing the pose of the object relative to the gripper or vice-versa is the most simple/robust representation commonly used for picking an object.
  </p>

  We interpolate from some initial gripper pose to a pose with the right clearance above the object to guarantee we avoid any collisions.Then we do a simpler approach to the object. People do lots of interesting complicated algorithms to figure out how to move through space and just hand code the last movement often to avoid collision. 

  <p>
    To define the position of the gripper to move into to pick an object, pick whatever direction (in terms of axis) is the easiest relative to the object. A similar thinking applies to orientation. For this, it would be good to know what orientation the object is in. For a little red cube, it is hard to get its orientation from a perception system because it's symmetric. Then we get our pose $^{G_{pick}}X^{O_{initial}}$. We do the same for pre/post pick etc.
  </p>

  In code, $^BX^A_C \equiv$ <code>X_BA_C</code>. ${^WX^A_W} = X^A \equiv$ <code>X_A</code>

  <subsection id="2.0"><h1>Timing between key frames</h1>
    Sometimes the time to finish a segment between going from 1 key frame to another, is absolute. Sometimes, it's scaled based on the distance between the frames. 
  </subsection>
</section>

<section id="3"><h1>Interpolation between poses</h1>
  We need to figure out where the gripper needs to be at all times between the pick and place frames, i.e. we need to interpolate between the key poses.

  <subsection id="3.0"><h1>Interpolation between positions</h1>
    <p>
      Say, we had the following plot:
      <ul>
        <li>X-axis: time.</li>
        We can specify when the pick and place should take place and all the other intermediate frames specified in time.

        <p>
          <li>Y-axis: ${^WP^G_{W_x}}$</li>
          The position of the gripper in the world frame is a 3 element vector but we only consider the x component.
        </p>
      </ul>
    </p>

    <div class="container">
      <figure>
        <img style="height:80px; width:auto"
        src="../../../figures/manipulation/39a_positionInterpolation.png"/>
        <figcaption>
          Key frames between pick and place times
        </figcaption>
      </figure>
      <figure>
        <img style="height:80px; width:auto"
        src="../../../figures/manipulation/39b_positionInterpolation.png"/>
        <figcaption>
          First order interpolation
        </figcaption>
      </figure>
      <figure>
        <img style="height:80px; width:auto"
        src="../../../figures/manipulation/39c_positionInterpolation.png"/>
        <figcaption>
          Zero order hold
        </figcaption>
      </figure>
    </div>

    There are different ways of interpolating:
    <ul>
      <li>First order hold</li>
      It's called first order because the line joining 2 points has 1DOF i.e. the slope of the line. It's a simple straight line interpolation. Doing a first order interpolation for orientation requires a bit more care compared to doing it for positions.

      <p>
        <li>Zero order hold</li>
        Zero order hold would be if there was no interpolation between the points and we just did some staircase. It is not safe to run this on a robot.
      </p>
      
      <li>Higher order interpolations</li>
      They give nice curves between key poses.
    </ul>
  </subsection>
  
  <subsection id="3.1"><h1>Problems faced when interpolating between orientations</h1>
    <subsubsection><h1>Choice of representation</h1>
      Some representations look simple to interpolate but then would blow up - could potentially go through bad states in the middle. 

      <p>
        There are roll pitch yaw values that represent very similar orientations but are actually very far in the values. Trying to go between one and another representation of roll pitch yaw might take the robot through extremely large numbers. This goes along with gimbal lock. 
      </p>
    </subsubsection>

    <subsubsection><h1>Simple linear interpolation for orientations is not possible</h1>
      Let's take a simple 2D rotation matrix example. We have a 2D rotation written as a function of some angle $\theta$ which will rotate a $2 \times 1$ vector by $\theta$ degrees:
      $$
        R(\theta) = \begin{bmatrix}
        c\theta & -s\theta \\
        s\theta & c\theta
        \end{bmatrix}
      $$

      Let's say we have 2 rotation matrices for rotating by $90^0$ and the other by $0^0$.
      $$
        R(0) = \begin{bmatrix}
        1 & 0 \\
        0 & 1
        \end{bmatrix} \quad
        R(\frac{\pi}{2}) = \begin{bmatrix}
        0 & -1 \\
        1 & 0
        \end{bmatrix}
      $$

      <div class="container">
        <figure>
          <img style="height:80px; width:auto"
          src="../../../figures/manipulation/40a_0rotation.png"/>
          <figcaption>
            Rotation of a unit frame <code>Rotz(0)</code>
          </figcaption>
        </figure>
        <figure>
          <img style="height:80px; width:auto"
          src="../../../figures/manipulation/40b_90rotation.png"/>
          <figcaption>
            Rotation of a unit frame <code>Rotz(90)</code>
          </figcaption>
        </figure>
      </div>
      If we were to linearly interpolate between the 2 angles, we wouldn't get $45^0$ i.e. we'd get $\frac{1}{2}$s in the rotation matrix instead of $\frac{1}{\sqrt{2}}$s. We can't just interpolate orientations.
    </subsubsection>

    <subsubsection><h1>Why don't we have such problems with angular velocities</h1>
      Angles wrap around every $2\pi$ and velocities don't. If we rotate by $\pi$, $-\pi$ or $3\pi$, we'll end up at the same place. But $100rad/s$ is still different than every other positive radian per second.

      <p>
        In 2D, you can represent everything with a scalar, a single rotation. When the wrapping effect is seen, flip back from polar coordinates or rectangular coordinates and we can always figure out the angles between two locations. In 2d, if we think about a rotation taking us around a unit sphere - a point moving around the unit sphere, the angular velocity is just the tangent on that and it's well behaved.
      </p>
 
      In 3d, there are rotations/angles that we can get to from many paths and picking a unique inverse of it is messy. 
    </subsubsection>
  </subsection>

  <subsection id="3.2"><h1>The right way to interpolate between orientations</h1>
    People typically use:
    <ul>
      <li>The quaternion representation to get around gimbal lock</li>
      <li><i>SLERP (Spherical linear interpolation)</i> to get a smooth first order interpolation</li>
    </ul>
  </subsection>

</section>

<section id="4"><h1>Forward kinematics problem</h1>
  <subsection id="4.0"><h1>Description</h1>
    $$
      X^B = f^B_{kin}(q)
    $$  

    In this mathematical equation (actual implementation in code is different):
    <br>
    $q$ is the vector of positions.
    <br>
    $X$ is the pose in the world.
    <br>
    $f_{kin}$ is the FK of the body.
    <br>
    $B$ stands for body.
    <br>
    $G$ stands for gripper if it was used instead of $B$.    
    
    <p>
      The mapping from joint angles to poses is called the <i>Forward Kinematics problem</i>. Looking at the 2D rotation matrix above:
      $$
        R(\theta) = \begin{bmatrix}
        c & -s \\
        s & c     
        \end{bmatrix}
      $$
    </p>

    If we have joint angle $\theta$ and we want to turn it into a rotation or a pose then it is almost always going to be a nonlinear map from the joint angles into the poses. The matrix above is maybe the simplest example of it.
  </subsection>

  <subsection id="4.1"><h1>Computing the pose of the EE using FK</h1>
    Given that we've set all the joint angles:
    <ul>
      <li>Compute pose of the EE relative to the wrist</li>
      We find the rotation matrix for the rotation joint which is just a relative pose.

      <p>
        <li>Chain it backwards all the way to the world coordinates</li>
      </p>
    </ul>

    The math is simple because each individual joint is just describing a small rotation matrix kind of operation on a relative transform from right before the robot's joint until right after the robot's joint. That's how robots are specified in robot description files as relative poses of each link - 6 numbers: x, y, z, roll, pitch, yaw. Joints are just operations that will make a transformation from the pre joint frame to the post-joint frame. 

  </subsection>

  <subsection id="4.2"><h1>Defining $q$</h1>
    <p>
      $q$ should be defined in such a way so as to be sufficient to tell us where all the attached bodies are in the world. In iiwa that's bolted down, all we need are 7 numbers of the different rotations of the different joints. But if we have a red brick on the table, we need enough something in $q$ to be able to eventually pull out the pose. 
    </p>

    In code, we define a $3\times 3$ rotation matrix for each joint based on the corresponding joint angle. We can then go through a series of frame transformations (through all the joints) to get the full kinematics. 
    <ul>
      <li>Iiwa</li>
      In iiwa, it's a $7\times 1$ vector of rotational joint angles representing the revolute joints. It's 7 because we choose to use quaternions in the coordinate representation to avoid gimbal locks and singularities.

      <p>
        <li>Allegro hand</li>
        It has 4 fingers with 4 links per finger. Total number of joint angles is 16. Plus, 7 numbers to configure its position in space. 
      </p>

      <li>Allegro hand picking up a brick</li>
      23 numbers for the hand and 7 for the brick. The kinematics problem then becomes going from the 30 numbers (representing q) to some pose of the brick and hand.
    </ul>
  </subsection>

  <subsection id="4.3"><h1>Drake implementation</h1>
    To compute the FK in drake, we need to specify the frames to get the pose of the desired frame relative to some other frame expressed in some other frame.

    <p>
      The context is taken as the argument instead of $q$ because the kinematics can be parameterized. If we were designing a robot and we wanted to optimise the length of a link for instance. Then we'd like the kinematics to also be a function of the link lengths or some other quantities. Hence, this is useful.
    </p>

    The <i>context</i> is just state + parameters + time; it's just the structure that wraps it. 

    <p>
      Very often, quaternions is used to represent the position/orientation and rotation matrix is used to represent the pose $X$.
    </p>
  </subsection>
</section>

<section id="5"><h1>Inverse kinematics</h1>
  We want to go from poses in the world to joint positions.
  $$
    q = (f^B)^{-1}(X^B)
  $$
  
  This is a nonlinear complicated function called <i>inverse kinematics</i>. It's not necessarily a unique mapping - there can be multiple $q$s that get the same pose in the world. There could also be no solutions. Going the other way is more straight forward.   
  
  <p>
    Sometimes we use the IK directly but oftentimes we do not because if our IK engine gives us slightly different answers for very similar poses, then it might involve crazy arm movements to achieve it. We want to send smooth commands to the robot so that it's not jumping around to different solutions. When we specify IK, we normally also specify additional requirements for continuity/smoothness/centering etc. An example: if we had enough DOF in an arm and there were multiple solutions for joint angles given a fixed pose for the hand, then the IK engine could ask for different joint angles (for the same hand pose) every 0.0001 seconds. That wouldn't be good. 
  </p>
</section>

<section id="6"><h1>Differential IK</h1>
  <subsection id="6.0"><h1>Description</h1>
    In order to encourage smoothness between joint angles instead of IK we use the differential form of the kinematics where we examine how an incremental change in $q$ makes an incremental change in the pose $X$. If we want to make a relatively small change in a certain direction to the current pose, we figure out the incremental change in $q$ we need to make. Differential IK isn't defined perfectly everywhere but partial derivatives exist everywhere. 

    $$\begin{align*}
      \underbrace{dX^B}_{\text{Incremental change} \atop \text{in pose}} &= 
      \frac{\partial{f^B}(q)}{\partial{q}}
      
      \underbrace{dq}_{\text{Incremental change} \atop \text{in joint angle}} \\

      \underbrace{V^B}_{\text{Spatial} \atop \text{velocity}} 
      &= \underbrace{J^B(q)}_{\text{Jacobian}} \quad \dot{q} \\

    \end{align*}$$ 

    The Jacobian is a function of the current joint angles. 
  </subsection>
  
  <subsection id="6.1"><h1>Spatial velocity</h1>
    In order to start thinking about differential quantities (like the Jacobian), we'll need to know the joint velocity ($\frac{dq}{dt}$) and some pose velocity.

    <p>
      Just like we have spatial algebra for positions and orientations, we have it for velocities called <i>spatial velocity</i> which has a translation component and an orientation component:

      $$\begin{bmatrix}
        \omega \\ v
      \end{bmatrix}$$

      $\omega$ is the <i>angular velocities</i>, a $3 \times 1$ vector 
      <br>
      $v$ is the <i>translational velocities</i>, a $3 \times 1$ vector 
      <br>
      Spatial velocity is a $6 \times 1$ vector 
    </p>

    In pose, there's no canonical choice. In orientation, for example, we have problems based on the chosen representation. That's why we constantly move between representations. However there is a canonical choice for angular velocity. It is 3 numbers which are the rotations around the major axes. This notion of angular velocity simplifies everything once we get to velocities and spatial accelerations. 
  </subsection>

  <subsection id="6.2"><h1>Geometric jacobian</h1>
    <p>
      Geometric jacobian is always a function of $q$. It is a position dependent matrix.
    </p>
    Purely in terms of <n>representation</n> of spatial velocity, we have a canonical choice. The problem is that because we have so many different choices for $q$ and $X$, we have many different possible Jacobians to determine how we're going to go from joint angles/velocities to some spatial velocity. 
    
    <p>
      A <i>geometric jacobian</i> takes joint velocities and maps that to spatial velocity vectors. It's not quite $\frac{\partial{f^B}(q)}{\partial q}$. It's this plus the change of coordinates into the spatial vectors. The analytic jacobian is the true partial derivative. But it's not recommended as much. There are cases where we might want that but almost always spatial velocities is recommended. 
    </p>

    Floating Allegro hand + brick: 30 numbers, 23 positions but only 22 velocities. For example, we'll have an extra term if we use the quaternion representation. But, this needs to turn into the $6 \times 1$ spatial velocity vector. So, there is a change of representation that takes place.
  </subsection>

  <subsection id="6.3"><h1>Joint velocity</h1>
     How do we represent $\dot{q}$? The joint position vector (because of say quaternion representation) is often bigger than the joint velocity vector. And the spatial joint velocity can only take 6 numbers. Joint velocities won't always directly equal $\frac{dq}{dt}$ because of the choice of representation. We can map between them though. 
  </subsection>

  <subsection id="6.4"><h1>Inverse Jacobian</h1>
    <subsubsection><h1>The problem</h1>
      $$
        \dot{q}_{\scriptscriptstyle{7 \times 1}} = 
        [J^B_{\scriptscriptstyle{6\times{7}}}(q)]^{-1} 
        V^B_{\scriptscriptstyle{6\times{1}}}
      $$
      The matrix dimensions are written for iiwa where there are 7 joints and hence 7 $\dot{q}$s. However, we can't take the inverse of a non-square matrix. Hence, this equation only represents what we would like to do conceptually.
    </subsubsection>

    <subsubsection><h1>Pseudo Inverse Jacobian</h1>
      $$
        \dot{q} = [J^B(q)]^{\dagger}V^B
      $$
      We actually do a pseudo inverse. It has magical properties. It works (i.e. it's well-defined)even if the matrix isn't square. When things are not square, we could have infinitely many or no solutions. <code>pinv</code> does the right thing. 

      <p>
        In the infinitely many solutions case, it will pick the one that's minimum norm in the least squares norm. It'll find the smallest solution. In this case it'd be the smallest joint velocities that achieve the desired velocity. If there are no solutions then it doesn't just fail it actually does its best effort and tries to find $\dot{q}$ that is as close to matching the equality as possible. The pseudo inverse is awesome. It just outputs a matrix.
      </p>

    </subsubsection>
  </subsection>
</section>

<section id="7"><h1>The controller</h1>
  <div class="container">
    <figure>
      <img style="height:60px; width:auto"
      src="../../../figures/manipulation/41_pseudoInverseController.png"/>
      <figcaption>
        $\dot{q}^d$ is desired IIWA velocities, $V^{G^d}$ is desired spatial velocities.
      </figcaption>
    </figure>
  </div>

  To compute the desired velocities, the pseudo inverse controller (PIC) needs:
  <ul>
    <li>a model of the robot (inside the block)</li>
    <li>current positions of the robot $q$</li>
    We could use the commanded/desired or the measured position. The latter could be noisy so it's more stable to use the former.

    <p>
      If actual positions were used instead, even in simulation, we'd get a good solution but then in the <i>null space</i> (in the multiple solution dimension) the elbow will walk around a little. It's a subtlety of the way these things feedback with the numerical precision of the integrator.
    </p>

    <li>commanded desired spatial velocities $V^{G^d}$</li>
  </ul>

  PIC takes in commanded poses and outputs commanded joint positions (integrator included). The manipulation station takes in desired position commands (not velocities), so we need an integration step to turn desired velocities into position commands. The initial conditions of the integrator need to match that of the robot, else the robot will go to a very bad initial condition at time zero. 

  <p>
    The manipulation station outputs the actual/measured iiwa positions. The trajectory generator converts the planned sketch into a spatial velocity trajectory. It feed into the PIC, which feeds into the integrator which feeds the manipualtion station.
  </p>

  <subsection id="7.0"><h1>Limitations</h1>
    The chapter's notebook has sliders that rotates the joints of the arm which then changes the Jacobian, which is printed.

    <p>
      If there are no solutions, the controller will come up with the best possible solution. It will find the minimum norm. When is it not enough? At a singularity. What does a singularity mean? 
    </p>

    <button class="accordion">Matrix rank</button>
    <div class="panel">
      <p></p>
      The <i>rank of a matrix</i> is the maximum number of linearly independent rows or columns in that matrix. In robotics, the <i>rank of a matrix</i> is used to determine the <i>manipulability</i> or <i>controllability</i> of a robot arm. It indicates the number of independent directions in which the end-effector of the arm can move. The <i>rank of the Jacobian matrix</i>, which relates the joint velocities to the end-effector velocities, provides valuable information about the arm's mobility and its ability to reach different positions and orientations in its workspace.

      <p>
        If the rank of the Jacobian matrix is equal to the number of DOF of the robot arm, it means that the arm can move freely in all possible directions within its workspace. This implies that the robot arm is fully controllable and can reach any desired position and orientation within its reachable workspace.
      </p>
      
      On the other hand, if the rank of the Jacobian matrix is less than the number of DOF, it suggests that the arm is kinematically constrained. This can occur when certain joints of the arm are mechanically linked or when there are other physical limitations that restrict the arm's movement. In such cases, the arm may have limited mobility and may not be able to reach all desired positions and orientations in its workspace.

      <p>
        In summary, the rank of a matrix, particularly the Jacobian matrix, provides insight into the controllability and mobility of a robot arm. A higher rank indicates greater freedom of movement, while a lower rank suggests constraints or limitations on the arm's motion.
      </p>
    </div>

    When the arm changes from having good solutions to having no or infinite solutions, there is the possibility of the rank of the matrix $[J^B(q)]^{-1}_{\scriptscriptstyle{6\times{7}}}$ to drop. Since we are trying to find $q$, we only care about the row rank. It is a good case, when we have 7 $\dot{q}$s and only 6 desired velocities, since we have multiple solutions. We never want the rank to drop below 6.

    <p>
      A robot will break before it drops rank. What actually happens is, as the robot approaches losing rank the inverse gets poorly conditioned and we'll get very big commanded velocities out which will cause the robot to hit a joint or velocity limit and it'll shut down.
    </p>

    The relative distance (numerically) between the smallest and largest singular value is not what matters. If the smallest singular value gets close to 0, we'd get large velocities on inverting the matrix. So it's useful to plot the smallest singular value. 
    
    <p>
      One easy way to get the arm in a singular state is to straighten it. There could be other singularities. When an arm is pretty extended and we try to extend it more, things are going to get bad.
    </p>

  </subsection>
</section>
</details>
</chapter>

</body>
</html>
