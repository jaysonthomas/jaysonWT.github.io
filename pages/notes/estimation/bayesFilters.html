
<!DOCTYPE html>
<html>
<head>
  <title>Bayes Filters</title>
  <meta name="Bayes Filters" content="text/html; charset=utf-8;" />
  <script type="text/javascript" src="../../../logbook.js"></script>

  <script src="../../../logbook-mathjax-config.js" defer></script> 
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/atom-one-light.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <link rel="stylesheet" type="text/css" href="../../../logbook.css" />
</head>

<body onload="loadChapter('');">  

  <div data-type="titlepage" pdf="no">
    <header>
      <h1><a href="../../../index.html" style="text-decoration:none;">Logbook</a></h1>
      <p style="font-size: 18px;"><a href="../../../pages/bio/jjwt.html">Jayson Wynne-Thomas</a></p>
      <p style="font-size: 14px; text-align: right;"> 
        Last modified <span id="last_modified"></span>.</br>
        <script>
        var d = new Date(document.lastModified);
        document.getElementById("last_modified").innerHTML = d.getFullYear() + "-" + (d.getMonth()+1) + "-" + d.getDate();</script>
      </p>
    </header>
  </div>
  
  <div id="main" class="sidebar1">
    <span style="font-size:10px;cursor:pointer" onclick="openNav()">&#9776;</span>
  </div>

  <div id="mySidenav" class="sidebar">
  
<a href="#0">Key ideas</a>
<ul class="no-bullets">
  <li><a href="#0.0">Inclusion of system dynamics</a></li>
  <li><a href="#0.1">Uncertainty in the estimate</a></li>
</ul>
<a href="#1">The algorithm</a>
<a href="#2">Flavours of the bayes filter</a>
</div>

<chapter style="counter-reset: chapter 0"><h1>Bayes Filters</h1>
<section id="0"><h1>Overview</h1>
  <subsection><h1>The main aim</h1>
    The main aim is to maintain an accurate and responsive state estimate of a continuously changing system. No matter how clever one is with noisy sensor data, it is not possible to maintain a robust and responsive estimate of a state (eg. position of a moving vehicle), unless the estimator is also made aware of the controls the system is commanded. 

    <p>
      Bayes filters allow the integration of measurements and control in a continuous space, incorporating them into the state estimator to find a continuous state estimate.
    </p>
  </subsection>

  <subsection id="0.0"><h1>The 2 key steps</h1>
    Bayes Filter is a general framework for thinking about state estimation. Its key idea involves alternating between 2 steps to maintain a belief of a state:
    
    <ul>
      <li>Prediction step</li>
      A future state can be predicted using the control actions commanded of the system and the system's dynamics; in other words, using the predicted effects of the control actions.

      <p>
        <li>Measurement update step</li>
        Observations can be used to correct the prediction.
      </p>
    </ul>
  </subsection>

  <subsection id="0.1"><h1>Uncertainty in the estimate after each step</h1>
    <div class="container">
      <figure>
        <img style="height:120px; width:auto"
        src="../../../figures/drone/35_bayesNotAPoint.png"/>
        <figcaption>
          Not a point
        </figcaption>
      </figure>

      <figure>
        <img style="height:120px; width:auto"
        src="../../../figures/drone/35_bayesDistribution.png"/>
        <figcaption>
          But a distribution
        </figcaption>
      </figure>
    </div>

    The uncertainty in the state estimate is a distrbution and not a point estimate. 
    
    <ul>
      <li>After the prediction step</li>
      The current state is projected forward based on the control input. This prediction will be noisy because of <n>imperfections in the system model</n>, causing an increase in the uncertainty and hence our belief to spread out.

      <p>
        If we had a perfect transition model with no noise, we could predict forever without the need to make any measurements. However, because there is noise, if we predicted forever, the transition noise would keep increasing after each step.
      </p>

      <li>After the measurement step</li>
      The uncertainty goes down even though the measured information from the external world is noisy.
    </ul>
  </subsection>
</section>

<section id="1"><h1>The algorithm</h1>
  The algorithm as described here makes the assumption that the system is run in simulation i.e. we can execute a control action and receive a measurement of the system after the control is applied in the same time step. At the end of every timestep, we have a belief of the system's state. In terms of computing the input control, we need both a reference trajectory and the system's state at the end of the previous timestep.

  <ul>
    <li>Compute control</li>
    $$
      u_t = f(bel(x_{t-1}))
    $$

    At timestep $t$, we use the previous belief of the system's state to get a new control value.

    <p>
      <li>Predict</li>
      $$\begin{align*}
        \bar{bel}(x_t) &= f(bel(x_{t-1}), u_t, \Delta{t}) \\
                    &= \int{p(x_t|u_t, x_{t-1}) \; bel(x_{t-1}) \; \Delta{t}} 
      \end{align*}$$

      We then use $u_t$ to predict the system's state in the next timestep.

      <p>
        In general, calculating $\bar{bel}$ is an integral. Depending on how $\bar{bel}$ and $bel$ are represented, the integral might take a closed form. When the belief is Gaussian, this takes the form of matrix operations over the mean and covariance matrix. <m>What does the probability term look like IRL?</m>
      </p>
    </p>

    <li>Read sensor and measurement update</li>
      $$\begin{align*}
        bel(x_t) &= f(\bar{bel}(x_t), z_t) \\
                &= \eta \; p(z_t|x_t) \; \bar{bel}(x_t)
      \end{align*}$$

      Bayes rule is used to (calculate a new distribution) incorporate the new sensor measurement with the predicted state to update our current belief. 
  </ul>

  Notice the inputs to the different functions - because of the Markov property, we don't need to remember all of our previous controls and measurements. <m>What does $\eta$ represent?</m>
</section>

<section id="2"><h1>Flavours of bayes filter</h1>
  <div class="container">
    <figure>
      <img style="height:100px; width:auto"
      src="../../../figures/drone/34_bayesFilterFlavours.png"/>
      <figcaption>
        Different implementations of bayes filter
      </figcaption>
    </figure>
  </div>

  <ul>
    <li><a href="kalmanFilter.html">Kalman Filter</a></li>
      Kalman filter is a specific implementation of the bayes filter where everything is represented as Gaussians.

    <p>
    <li><a href="ekf.html">Extended Kalman Filter (EKF)</a></li>
      Here, everything is Gaussian but the state or observation models are non-linear. By calculating the Jacobian of these models, we can linearise around the current estimated state to make things Gaussian again, and then everything works out just like a Kalman Filter. These linear approximations have to be made at every time step. EKF is hard to implement because even the smallest amount of error throws the estimator.

    <p>
      In both KF and EKF, the beliefs are described by Gaussians.
    </p>
    </p>

    <li><a href="ukf.html">Unscented Kalman Filter (UKF)</a></li>
    Here, a non-linear state is estimated using special particles which can be passed through a non-linear system instead of linearizing the system as in the case of the EKF. It is simpler to implement.

    <p>
      <li>
        In Particle Filter, particles or samples are used to estimate a non-linear distribution which is not Gaussian. 
      </li>
    </p>
  </ul>
</section>
</chapter>

</body>
</html>
