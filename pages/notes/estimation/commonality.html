
<!DOCTYPE html>
<html>
<head>
  <title>Estimation: Commonality in approaches</title>
  <meta name="Estimation: Commonality in approaches" content="text/html; charset=utf-8;" />
  <script type="text/javascript" src="../../../logbook.js"></script>

  <script src="../../../logbook-mathjax-config.js" defer></script> 
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/atom-one-light.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <link rel="stylesheet" type="text/css" href="../../../logbook.css" />
</head>

<body onload="loadChapter('');">  

  <div data-type="titlepage" pdf="no">
    <header>
      <h1><a href="../../../index.html" style="text-decoration:none;">Logbook</a></h1>
      <p style="font-size: 18px;"><a href="../../../pages/bio/jjwt.html">Jayson Wynne-Thomas</a></p>
      <p style="font-size: 14px; text-align: right;"> 
        Last modified <span id="last_modified"></span>.</br>
        <script>
        var d = new Date(document.lastModified);
        document.getElementById("last_modified").innerHTML = d.getFullYear() + "-" + (d.getMonth()+1) + "-" + d.getDate();</script>
      </p>
    </header>
  </div>
  
  <div id="main" class="sidebar1">
    <span style="font-size:10px;cursor:pointer" onclick="openNav()">&#9776;</span>
  </div>

  <div id="mySidenav" class="sidebar">
  
<a href="#0">Fundamental principles</a>
<a href="#1">Measurement model</a>
<a href="#2">Mathematical model of noise</a>
<a href="#3">Dimensions</a>
<a href="#4">State</a>
<a href="#5">Estimation covariance</a>
<ul class="no-bullets">
  <li><a href="#5.0">Purpose</a></li>
  <li><a href="#5.1">Computation</a></li>
</ul>
<a href="#6">Measurement noise covariance</a>
<ul class="no-bullets">
  <li><a href="#6.0">Purpose</a></li>
  <li><a href="#6.1">Computation</a></li>
</ul>
<a href="#7">When Estimation and Measurement noise covariance becomes equal</a>
</div>

<chapter style="counter-reset: chapter 0"><h1>Estimation: Commonality in approaches</h1>
<section id="0"><h1>Fundamental principles</h1>
  The more measurements that can be collected, the more accurate the estimate will be.
</section>

<section id="1"><h1>Measurement model</h1>
  A measurement model encapsulated in the Jacobian $H$:
  <ul>
    <li>Projects a state into its measurement space or</li>
    <li>Maps a state to a measurement</li>
  </ul>

  <p>
    In the simplest form, a measurement equation looks like:
    $$
      y = Hx + v
    $$
  </p>

  $z_t$ or $y_t$ represents an observation or a measurement made at timestep $t$.
</section>

<section id="2"><h1>Mathematical model of noise</h1>
  It is not possible to know exactly how much noise gets added to each individual measurement. However, the distribution from which the noise is sampled can be modeled. A <i>noise distribution</i> captures the imperfections in a sensor, by modeling the likelihood of making measurement $z$ given the system is in state $x$, $p(z|x)$. 

  <p>
    Noise distributions are often modeled as or assumed to be a zero-mean gaussian with some covariance $R$. To each measurement, a noise $v$ is added, sampled from the gaussian $\mathcal{N}(0, R)$. The most likely measurement is centred on the true value of whatever the sensor measures with some covariance.

    $$
      v \sim \mathcal{N}(0, R)
    $$
  </p>
</section>

<section id="3"><h1>Dimensions</h1>
  <ul>
    <li>$x$ is the unknown state vector to be estimated of size $m$</li>
    <li>$y$ is the vector of $k$ noisy measurements</li>
  </ul>
</section>

<section id="4"><h1>State</h1>
  $x_t$ is the unknown state at timestep $t$. $\hat{x}_t$ is the estimate of the state at time $t$.
</section>

<section id="5"><h1>Estimation covariance</h1>
  <subsection id="5.0"><h1>Purpose</h1>
    The estimation covariance matrix $P$ represents the uncertainty in the estimated state variables. It quantifies how much the estimated state variables are expected to vary from their true values due to uncertainties in the system model and the measurements.

    <p>
      It helps in determining how much weight should be given to new measurements versus the current state estimate. A larger $P$ means higher uncertainty in the current state estimate, which results in giving more weight to new measurements.
    </p>
  </subsection>
  <subsection id="5.1"><h1>Computation</h1>
    In Kalman filter, $P$ is updated recursively based on the process model and the measurement update. It combines information from both the model predictions and the measurements to give an overall uncertainty of the state estimate.
  </subsection>
</section>

<section id="6"><h1>Measurement noise covariance</h1>
  <subsection id="6.0"><h1>Purpose</h1>
    The measurement noise covariance matrix represents the uncertainty in the measurement process itself. It quantifies the expected variance and correlation of the measurement noise.

    <p>
      It influences how much trust should be placed on measurements. Higher values in $R$ indicate higher measurement noise, which means less trust in measurements and more reliance on the model prediction.
    </p>
  </subsection>
  <subsection id="6.1"><h1>Computation</h1>
    $R$ is usually specified based on known characteristics of measurement sensors or systems. It is often assumed to be constant or known a priori.
  </subsection>
</section>

<section id="7"><h1>When Estimation and Measurement noise covariance becomes equal</h1>
  <subsubsection><h1>Initial conditions</h1>
    At the initial time step, if the initial state estimate is set to be the same as the measurement and if the initial estimate is purely based on the measurement, then $P$ might initially be equal to $R$. However, as the estimation process proceeds, $P$ and $R$ will diverge due to the incorporation of process dynamics and multiple measurements.
  </subsubsection>

  <subsubsection><h1>Simple systems</h1>
    In some simplified systems where the model is very straightforward and the process noise is negligible, $P$ might be driven primarily by the measurement noise. Even in such cases, $P$ would not be exactly equal to $R$ but could be influenced by it significantly.
  </subsubsection>

  <subsubsection><h1>Steady-state conditions</h1>
    In some steady-state conditions of a linear system with constant noise characteristics, the asymptotic behavior of $P$ might lead it to a value that reflects the steady-state influence of $R$. Even then, $P$ is not equal to $R$ but is influenced by $R$.
  </subsubsection>
</section>
</chapter>

</body>
</html>
