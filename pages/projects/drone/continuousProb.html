<!DOCTYPE html>

<html>

  <head>
    <title>Ch. 1 - Introduction</title>
    <meta name="Ch. 1 - Introduction" content="text/html; charset=utf-8;" />
    <link rel="canonical" href="https://jaysonthomas.github.io/interviewPrep.html" />

    <script type="text/javascript" src="../../../chapters.js"></script>
    <script type="text/javascript" src="../../../htmlbook/book.js"></script>

    <script src="../../../htmlbook/mathjax-config.js" defer></script> 
    <script type="text/javascript" id="MathJax-script" defer
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
    <script>window.MathJax || document.write('<script type="text/javascript" src="../../../htmlbook/MathJax/es5/tex-chtml.js" defer><\/script>')</script>

    <link rel="stylesheet" href="../../../htmlbook/highlight/styles/default.css">
    <script src="../../../htmlbook/highlight/highlight.pack.js"></script> <!-- http://highlightjs.readthedocs.io/en/latest/css-classes-reference.html#language-names-and-aliases -->
    <script>hljs.initHighlightingOnLoad();</script>

    <link rel="stylesheet" type="text/css" href="../../../notes.css" />
  </head>

<body onload="loadChapter('manipulation');">

  <!-- The following division should be written on every page -->
<div data-type="titlepage" pdf="no">
  <header>
    <h1><a href="index.html" style="text-decoration:none;">Jayson's notes</a></h1>
    <p data-type="subtitle">Mostly control systems</p> 
    <p style="font-size: 18px;"><a href="http://people.csail.mit.edu/russt/">Jayson Thomas</a></p>
    <p style="font-size: 14px; text-align: right;"> 
      &copy; Jayson Thomas, 2020-2022<br/>
      Last modified <span id="last_modified"></span>.</br>
      <script>
      var d = new Date(document.lastModified);
      document.getElementById("last_modified").innerHTML = d.getFullYear() + "-" + (d.getMonth()+1) + "-" + d.getDate();</script>
    </p>
  </header>
</div>

<table style="width:100%;" pdf="no"><tr style="width:100%">
  <td style="width:33%;text-align:left;"><a class="previous_chapter"></a></td>
  <td style="width:33%;text-align:center;"><a href=../../../index.html>Table of contents</a></td>
  <td style="width:33%;text-align:right;"><a class="next_chapter" href=robot.html>Next Chapter</a></td>
</tr></table>

<!-- EVERYTHING ABOVE THIS LINE IS OVERWRITTEN BY THE INSTALL SCRIPT -->
<chapter style="counter-reset: chapter 0"><h1>Continuous Probability</h1>

<section id="table_of_contents"><h1>Table of Contents</h1>
  <ul>
    <li><a href="#1">Intro</a></li>
    <li><a href="#2">Cumulative distribution function</a></li>
    <li><a href="#3">Probability density function</a></li>
  </ul>
</section>

<section id="1"><h1>Intro</h1>
  An example of a continuous samples space is the real value position of a robot?
  <a href="https://t.ly/_1lN">Slide 10</a>.
  Random variables become extremely powerful in this case.
  Using real numbers to index the members of a continuous set is fairly intuitive.

  <p>
    When dealing with a continuous sample space,
    we can no longer say anything about the probability
    that our vehicle is at some specific location,
    because for a continuous sample space,
    the probability of any particular value will always be zero.
    We can only give the probability that our vehicle is in some region.
  </p>
</section>

<section id="2"><h1>Cumulative distribution function</h1>
  <figure>
    <img style="height:85px; width:auto"
    src="../../../figures/drone/8_cdf.png"/>
    <figcaption>
      CDF
    </figcaption>
  </figure>
  
  $$
    F_x(u) = p(x \leq u)
  $$

  The function describes the probability that a random variable $x$ is less than or equal
  to $u$. 
  
  <p>
    A <code>limit</code> is a value toward which an expression converges as one or more 
    variables approach certain values.
  </p>

  <p>
    $F$ will be monotonically increasing.
    The limit of $F$ as $u$ goes to $-\infty$ is $0$,
    and the limit as $u$ goes to $+\infty$ is $1$.
    It's important to understand that the index to the function is $u$,
    but it is sub-scripted by $x$ to indicate which random variable we're characterizing by
    the probability that the value of that random variable is less than $u$ or not.
  </p>
  <a href="https://t.ly/LlT8">Further reading</a>.
</section>
  
<section id="3"><h1>Probability density function</h1>
  $$
    f_x(u) = \frac{d}{du}F_x(u)
  $$
  It's the derivative of a CDF w.r.t. its index.

  <figure>
    <img style="height:100px; width:auto"
    src="../../../figures/drone/9_pdf.png"/>
    <figcaption>
      Uniform PDF for the position $x$ of a vehicle
    </figcaption>
  </figure>

  <p>
    Consider this uniform PDF for the position $x$ of a vehicle.
    It has the value 0.5 between $x$ equals zero and two, and zero everywhere else.
    The probability that the vehicle is in the region between 0 and 2 is found
    by calculating the area under the curve which would be $2*0.5$.
    In fact, the probability that a random variable will take a value between 
    $x_1$ and $x_2$, is given by the integral of the probability 
    density function from $x_1$ to $x_2$.

    $$
      p(x_1 < x < x_2) = \int^{x_2}_{x_1}f_x(x)dx = \int^{x_2}_{x_1}p(x)dx
    $$
  </p>
  <p>
    $f_x(x)$ isn't the probability, and it can easily be greater than $1$.
    But we do often write this density function as $p(x)$.
    This changes our notion of what it means to be a proper distribution.
    To be a proper density, $f_x(u)$ has to be greater than or equal to $0$,
    and the integral under the distribution has to be equal to $1$.
    Normalization implies finding a constant multiplier in
    front of this density function to make it integrate to $1$.
  </p>

  <a href="https://t.ly/1iwF">Ref</a> - why is it referred to as density?!
  <a href="https://t.ly/UB4I">Python code</a>.  
</section>

<section id="4"><h1>Parameters of a density function</h1>
  There are two common distributions - the Uniform,
  and the Gaussian, or the normal. We will use $\theta$ to collectively refer to all of
  the parameters that describe a particular distribution.  

  <p>
    One thing to emphasize is that $p$ of $x$ given $\theta$ is not
    the same thing as saying the function that
    describes the density of $x$ is parameterized by $\theta$.
    
    $$p(x|\theta) \neq p(x;\theta)$$
    
    $p(x|\theta)$ implies $\theta$ is a random variable itself.
  </p>

  <subsection><h1>Uniform distribution</h1>
    A uniform distribution can be parameterised in 2 ways:
    <ul>
      <li>Using $a$ and $b$ bounds</li>
      <figure>
        <img style="height:100px; width:auto"
        src="../../../figures/drone/10_udf.png"/>
      </figure>

      <li>Using the mean $\mu$ and the width $w$</li>
      <figure>
        <img style="height:100px; width:auto"
        src="../../../figures/drone/11_uniformDF_parameterisation.png"/>
      </figure>
      We could say the ends are $\mu - w$ and $\mu + w$,
      and the height of the distribution is $\frac{1}{2w}$.

      This distribution says all possible outcomes are equally likely,
      and sometimes this is the only thing we can do when we have
      no idea what the parametric family $p(x)$ actually is.
    </ul>
  </subsection>

  <subsection><h1>Gaussian or normal distribution</h1>
    The other distribution that we'll see most of the time in this module is the Gaussian.
    It's the familiar bell shaped curve,
    centered at some mu,
    with some width given by sigma.
    The density function is given by p of x equals one,
    divided by the square root of two pi,
    sigma squared times e to the negative x minus mu all square over two sigma squared.
    
    The Gaussian has a few interesting properties.
    First, it's symmetric around the mean mu.
    Second, the probability that x is within plus or minus one,
    standard deviation of mu is 68 percent,
    and the probability that it's within plus or minus three sigma is 99.7 percent.
    Notice how sigma describes how wide the distribution is.
    When sigma's small, that will make the peak narrow and sharp,
    and this implies that we have a high confidence of
    predicting what a sample drawn from x will be.
    When sigma is large the Gaussian,
    the normal distribution is very wide and flat,
    and that means we have poor knowledge of what exactly
    any given sample from this distribution is going to look like.
    
    So, you can see that a continuous distribution like a Gaussian,
    can actually be fully described by two parameters mu and sigma squared,
    and taking together, these parameters are the theta for this distribution,
    that I referenced earlier.
    Solving estimation problems often boils down to using data often from sensors,
    to come up with estimates for the values of these parameters.
  </subsection>
</section>

<section id="10"><h1>Musings</h1>
  <ul>
    <li>This distribution says all possible outcomes are equally likely</li>
    I disagree with this. Since the PDF gives the slope of the CDF (which actually gives
    the probability of a continuous event), a flat PDF doesn't mean the probability of
    1 event vs the next is the same but actually, the probability of the next has increased
    the same amount as the current vs the previous. The probability of the upper event
    is going to be greater than all the other events.
  </ul>
</section>

</chapter>
</body>
</html>

